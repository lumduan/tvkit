{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d461b920",
   "metadata": {},
   "source": [
    "# TVKit Comprehensive Sample Notebook\n",
    "\n",
    "**TVKit** is a Python library for TradingView's financial data APIs with real-time WebSocket streaming and comprehensive data export capabilities.\n",
    "\n",
    "## Features Covered in This Notebook\n",
    "\n",
    "- **OHLCV Data Fetching** - Historical and real-time financial data\n",
    "- **Data Export System** - Multiple formats (Polars DataFrame, JSON, CSV)\n",
    "- **Financial Analysis** - Technical indicators and data analysis\n",
    "- **Real-time Streaming** - Live market data updates\n",
    "- **Multi-symbol Operations** - Working with multiple financial instruments\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "```bash\n",
    "# Install tvkit with all dependencies\n",
    "pip install tvkit polars matplotlib seaborn\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e7a8b27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Analysis libraries loaded successfully\n",
      "üöÄ TVKit sample notebook initialized!\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "\n",
    "# TVKit imports\n",
    "from tvkit.api.chart.ohlcv import OHLCV\n",
    "from tvkit.export import DataExporter, ExportFormat\n",
    "from tvkit.api.utils import convert_timestamp_to_iso\n",
    "\n",
    "# Enable nested event loops for Jupyter notebooks\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Optional: Data analysis and visualization\n",
    "try:\n",
    "    import polars as pl\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "\n",
    "    ANALYSIS_AVAILABLE = True\n",
    "    print(\"‚úÖ Analysis libraries loaded successfully\")\n",
    "\n",
    "    # Use the imports to avoid F401 warnings\n",
    "    _ = pl, plt, sns\n",
    "except ImportError as e:\n",
    "    ANALYSIS_AVAILABLE = False\n",
    "    print(f\"‚ö†Ô∏è  Analysis libraries not available: {e}\")\n",
    "\n",
    "print(\"üöÄ TVKit sample notebook initialized!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aba7236",
   "metadata": {},
   "source": [
    "```markdown\n",
    "## Logging Configuration\n",
    "\n",
    "The following cell configures logging and warning settings to ensure clean, readable notebook output:\n",
    "\n",
    "- **Suppresses debug and info logs** from libraries such as `httpx`, `websockets`, and others, so only warnings and errors are shown.\n",
    "- **Disables most warnings** to avoid cluttering the notebook with non-critical messages.\n",
    "- This setup is recommended for interactive analysis, as it keeps the output focused on results and important issues.\n",
    "\n",
    "You can adjust the logging level or re-enable warnings if you need more detailed troubleshooting information.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3423a685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîá Debug logging disabled - clean output mode enabled\n"
     ]
    }
   ],
   "source": [
    "# Configure logging to suppress debug messages\n",
    "import logging\n",
    "import warnings\n",
    "\n",
    "# Set logging levels to reduce verbosity\n",
    "logging.getLogger().setLevel(logging.WARNING)\n",
    "logging.getLogger(\"httpcore\").setLevel(logging.WARNING)\n",
    "logging.getLogger(\"httpx\").setLevel(logging.WARNING)\n",
    "logging.getLogger(\"websockets\").setLevel(logging.WARNING)\n",
    "\n",
    "# Optionally suppress warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "print(\"üîá Debug logging disabled - clean output mode enabled\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ye1cco9abvl",
   "metadata": {},
   "source": [
    "## Basic OHLCV Data Fetching\n",
    "\n",
    "Let's start by fetching historical OHLCV (Open, High, Low, Close, Volume) data for Apple stock (AAPL) from NASDAQ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "os2zfplyv28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Fetched 10 OHLCV bars\n",
      "üìÖ Date range: 2025-07-30T05:49:00+00:00 to 2025-07-30T08:08:00+00:00\n",
      "\n",
      "üîç First 3 bars:\n",
      "  Bar 1: 2025-07-30 - Close: $1.67, Volume: 10,000\n",
      "  Bar 2: 2025-07-30 - Close: $1.67, Volume: 10,000\n",
      "  Bar 3: 2025-07-30 - Close: $1.67, Volume: 10,000\n"
     ]
    }
   ],
   "source": [
    "async def fetch_historical_ohlcv_data():\n",
    "    \"\"\"Fetch historical OHLCV data for Apple stock.\"\"\"\n",
    "    async with OHLCV() as ohlcv:\n",
    "        # Fetch last 100 daily bars for Apple\n",
    "        ohlcv_data = await ohlcv.get_historical_ohlcv(\n",
    "            exchange_symbol=\"NASDAQ:AAPL\",\n",
    "            interval=\"1D\",  # Daily intervals\n",
    "            bars_count=100,\n",
    "        )\n",
    "\n",
    "    # Display basic information\n",
    "    print(f\"üìä Fetched {len(ohlcv_data)} OHLCV bars\")\n",
    "    print(\n",
    "        f\"üìÖ Date range: {convert_timestamp_to_iso(ohlcv_data[0].timestamp)} to {convert_timestamp_to_iso(ohlcv_data[-1].timestamp)}\"\n",
    "    )\n",
    "\n",
    "    # Show first few bars\n",
    "    print(\"\\nüîç First 3 bars:\")\n",
    "    for i, bar in enumerate(ohlcv_data[:3]):\n",
    "        print(\n",
    "            f\"  Bar {i + 1}: {convert_timestamp_to_iso(bar.timestamp)[:10]} - Close: ${bar.close:.2f}, Volume: {bar.volume:,.0f}\"\n",
    "        )\n",
    "\n",
    "    return ohlcv_data\n",
    "\n",
    "\n",
    "# Run the function\n",
    "apple_data = await fetch_historical_ohlcv_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ctfisdz8tkq",
   "metadata": {},
   "source": [
    "## Data Export to Different Formats\n",
    "\n",
    "TVKit's `DataExporter` class provides seamless export to multiple formats including Polars DataFrames, JSON, and CSV files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "176h9cqcix4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìà Exporting to Polars DataFrame ...\n",
      "DataFrame shape: (10, 6)\n",
      "Columns: ['timestamp', 'open', 'high', 'low', 'close', 'volume']\n",
      "\n",
      "üìã First 5 rows:\n",
      "shape: (5, 6)\n",
      "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
      "‚îÇ timestamp           ‚îÜ open ‚îÜ high ‚îÜ low  ‚îÜ close ‚îÜ volume  ‚îÇ\n",
      "‚îÇ ---                 ‚îÜ ---  ‚îÜ ---  ‚îÜ ---  ‚îÜ ---   ‚îÜ ---     ‚îÇ\n",
      "‚îÇ str                 ‚îÜ f64  ‚îÜ f64  ‚îÜ f64  ‚îÜ f64   ‚îÜ f64     ‚îÇ\n",
      "‚ïû‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï°\n",
      "‚îÇ 2025-07-30T12:49:00 ‚îÜ 1.67 ‚îÜ 1.67 ‚îÜ 1.67 ‚îÜ 1.67  ‚îÜ 10000.0 ‚îÇ\n",
      "‚îÇ 2025-07-30T13:15:00 ‚îÜ 1.67 ‚îÜ 1.67 ‚îÜ 1.67 ‚îÜ 1.67  ‚îÜ 10000.0 ‚îÇ\n",
      "‚îÇ 2025-07-30T13:30:00 ‚îÜ 1.67 ‚îÜ 1.67 ‚îÜ 1.67 ‚îÜ 1.67  ‚îÜ 10000.0 ‚îÇ\n",
      "‚îÇ 2025-07-30T13:34:00 ‚îÜ 1.67 ‚îÜ 1.67 ‚îÜ 1.67 ‚îÜ 1.67  ‚îÜ 30000.0 ‚îÇ\n",
      "‚îÇ 2025-07-30T13:38:00 ‚îÜ 1.67 ‚îÜ 1.67 ‚îÜ 1.67 ‚îÜ 1.67  ‚îÜ 4000.0  ‚îÇ\n",
      "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
      "\n",
      "üíæ Exporting to JSON file...\n",
      "JSON exported to: tvkit_exports/apple_ohlcv_data.json\n",
      "\n",
      "üìä Exporting to CSV file...\n",
      "CSV exported to: tvkit_exports/apple_ohlcv_data.csv\n"
     ]
    }
   ],
   "source": [
    "async def demonstrate_data_export():\n",
    "    \"\"\"Demonstrate different data export formats.\"\"\"\n",
    "    exporter = DataExporter()\n",
    "\n",
    "    # 1. Export to Polars DataFrame\n",
    "    print(\"üìà Exporting to Polars DataFrame ...\")\n",
    "    df = await exporter.to_polars(apple_data, add_analysis=False)\n",
    "\n",
    "    print(f\"DataFrame shape: {df.shape}\")\n",
    "    print(f\"Columns: {df.columns}\")\n",
    "    print(\"\\nüìã First 5 rows:\")\n",
    "    print(df.head())\n",
    "\n",
    "    # 2. Export to JSON file\n",
    "    print(\"\\nüíæ Exporting to JSON file...\")\n",
    "    json_path = await exporter.to_json(\n",
    "        apple_data,\n",
    "        \"./tvkit_exports/apple_ohlcv_data.json\",\n",
    "        include_metadata=True,\n",
    "        indent=2,\n",
    "    )\n",
    "    print(f\"JSON exported to: {json_path}\")\n",
    "\n",
    "    # 3. Export to CSV file\n",
    "    print(\"\\nüìä Exporting to CSV file...\")\n",
    "    csv_path = await exporter.to_csv(\n",
    "        apple_data,\n",
    "        \"./tvkit_exports/apple_ohlcv_data.csv\",\n",
    "        include_metadata=True,\n",
    "        timestamp_format=\"iso\",\n",
    "    )\n",
    "    print(f\"CSV exported to: {csv_path}\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# Print Out of DataFrame\n",
    "df = await demonstrate_data_export()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hzfsd4vmgld",
   "metadata": {},
   "source": [
    "## Multi-Symbol Data Comparison\n",
    "\n",
    "Let's fetch data for multiple symbols and compare their performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "rkcencgahk8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Fetching data for multiple symbols...\n",
      "  üì• Fetching NASDAQ:AAPL...\n",
      "    ‚úÖ Got 30 bars\n",
      "  üì• Fetching NASDAQ:GOOGL...\n",
      "    ‚úÖ Got 30 bars\n",
      "  üì• Fetching NASDAQ:MSFT...\n",
      "    ‚úÖ Got 30 bars\n",
      "  üì• Fetching NYSE:TSLA...\n",
      "    ‚ùå Failed to fetch NYSE:TSLA: Invalid exchange:symbol 'NYSE:TSLA' after 3 attempts\n",
      "\n",
      "üìä Performance Summary (30-day period):\n",
      "------------------------------------------------------------\n",
      "NASDAQ:AAPL  | Change:  +7.70% | Range: $195.07-$216.23 | Avg Vol: 50,201,565\n",
      "NASDAQ:GOOGL | Change: +11.24% | Range: $162.00-$197.95 | Avg Vol: 41,594,066\n",
      "NASDAQ:MSFT  | Change:  +7.38% | Range: $472.51-$518.29 | Avg Vol: 18,052,562\n"
     ]
    }
   ],
   "source": [
    "async def compare_multiple_symbols():\n",
    "    \"\"\"Fetch and compare data for multiple symbols.\"\"\"\n",
    "    symbols = [\n",
    "        \"NASDAQ:AAPL\",  # Apple\n",
    "        \"NASDAQ:GOOGL\",  # Google\n",
    "        \"NASDAQ:MSFT\",  # Microsoft\n",
    "        \"NYSE:TSLA\",  # Tesla\n",
    "    ]\n",
    "\n",
    "    symbol_data = {}\n",
    "\n",
    "    print(\"üîÑ Fetching data for multiple symbols...\")\n",
    "\n",
    "    async with OHLCV() as ohlcv:\n",
    "        for symbol in symbols:\n",
    "            try:\n",
    "                print(f\"  üì• Fetching {symbol}...\")\n",
    "                data = await ohlcv.get_historical_ohlcv(\n",
    "                    exchange_symbol=symbol,\n",
    "                    interval=\"1D\",\n",
    "                    bars_count=30,  # Last 30 days\n",
    "                )\n",
    "                symbol_data[symbol] = data\n",
    "                print(f\"    ‚úÖ Got {len(data)} bars\")\n",
    "            except Exception as e:\n",
    "                print(f\"    ‚ùå Failed to fetch {symbol}: {e}\")\n",
    "\n",
    "    # Calculate performance metrics\n",
    "    print(\"\\nüìä Performance Summary (30-day period):\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "    for symbol, data in symbol_data.items():\n",
    "        if len(data) >= 2:\n",
    "            first_close = data[0].close\n",
    "            last_close = data[-1].close\n",
    "            change_pct = ((last_close - first_close) / first_close) * 100\n",
    "\n",
    "            avg_volume = sum(bar.volume for bar in data) / len(data)\n",
    "            max_high = max(bar.high for bar in data)\n",
    "            min_low = min(bar.low for bar in data)\n",
    "\n",
    "            print(\n",
    "                f\"{symbol:12} | Change: {change_pct:+6.2f}% | \"\n",
    "                f\"Range: ${min_low:.2f}-${max_high:.2f} | \"\n",
    "                f\"Avg Vol: {avg_volume:,.0f}\"\n",
    "            )\n",
    "\n",
    "    return symbol_data\n",
    "\n",
    "\n",
    "# Run multi-symbol comparison\n",
    "multi_symbol_data = await compare_multiple_symbols()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7hgnqfh186s",
   "metadata": {},
   "source": [
    "## Cryptocurrency and Forex Data\n",
    "\n",
    "TVKit supports various asset classes including cryptocurrencies and forex pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "uk9l107cma",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Fetching Cryptocurrency Data:\n",
      "----------------------------------------\n",
      "  üì• BINANCE:BTCUSDT...\n",
      "    ‚úÖ Latest: $117832.570000 (Vol: 1,898)\n",
      "  üì• BINANCE:ETHUSDT...\n",
      "    ‚úÖ Latest: $3777.690000 (Vol: 49,354)\n",
      "  üì• BINANCE:ADAUSDT...\n",
      "    ‚úÖ Latest: $0.765100 (Vol: 29,294,649)\n",
      "\n",
      "üìä Fetching Forex Data:\n",
      "----------------------------------------\n",
      "  üì• FX_IDC:EURUSD...\n",
      "    ‚úÖ Latest: $1.147160 (Vol: 35,549)\n",
      "  üì• FX_IDC:GBPUSD...\n",
      "    ‚úÖ Latest: $1.328300 (Vol: 33,648)\n",
      "  üì• FX_IDC:USDJPY...\n",
      "    ‚úÖ Latest: $148.969000 (Vol: 40,154)\n",
      "\n",
      "üìà Volatility Analysis (4-hour intervals, last 50 bars):\n",
      "------------------------------------------------------------\n",
      "\n",
      "Cryptocurrency:\n",
      "  BINANCE:BTCUSDT      | Volatility: 0.546% | Latest: $117832.570000\n",
      "  BINANCE:ETHUSDT      | Volatility: 1.196% | Latest: $3777.690000\n",
      "  BINANCE:ADAUSDT      | Volatility: 1.577% | Latest: $0.765100\n",
      "\n",
      "Forex:\n",
      "  FX_IDC:EURUSD        | Volatility: 0.193% | Latest: $1.147160\n",
      "  FX_IDC:GBPUSD        | Volatility: 0.173% | Latest: $1.328300\n",
      "  FX_IDC:USDJPY        | Volatility: 0.230% | Latest: $148.969000\n"
     ]
    }
   ],
   "source": [
    "async def fetch_crypto_and_forex_data():\n",
    "    \"\"\"Demonstrate fetching cryptocurrency and forex data.\"\"\"\n",
    "\n",
    "    # Different asset classes\n",
    "    symbols = {\n",
    "        \"Cryptocurrency\": [\n",
    "            \"BINANCE:BTCUSDT\",  # Bitcoin\n",
    "            \"BINANCE:ETHUSDT\",  # Ethereum\n",
    "            \"BINANCE:ADAUSDT\",  # Cardano\n",
    "        ],\n",
    "        \"Forex\": [\n",
    "            \"FX_IDC:EURUSD\",  # EUR/USD\n",
    "            \"FX_IDC:GBPUSD\",  # GBP/USD\n",
    "            \"FX_IDC:USDJPY\",  # USD/JPY\n",
    "        ],\n",
    "    }\n",
    "\n",
    "    all_data = {}\n",
    "\n",
    "    async with OHLCV() as ohlcv:\n",
    "        for category, symbol_list in symbols.items():\n",
    "            print(f\"\\nüìä Fetching {category} Data:\")\n",
    "            print(\"-\" * 40)\n",
    "\n",
    "            category_data = {}\n",
    "\n",
    "            for symbol in symbol_list:\n",
    "                try:\n",
    "                    print(f\"  üì• {symbol}...\")\n",
    "                    data = await ohlcv.get_historical_ohlcv(\n",
    "                        exchange_symbol=symbol,\n",
    "                        interval=\"240\",  # 4-hour intervals\n",
    "                        bars_count=50,\n",
    "                    )\n",
    "                    category_data[symbol] = data\n",
    "\n",
    "                    # Show latest price\n",
    "                    latest = data[-1]\n",
    "                    print(\n",
    "                        f\"    ‚úÖ Latest: ${latest.close:.6f} (Vol: {latest.volume:,.0f})\"\n",
    "                    )\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"    ‚ùå Failed: {e}\")\n",
    "\n",
    "            all_data[category] = category_data\n",
    "\n",
    "    # Calculate volatility for each asset\n",
    "    print(\"\\nüìà Volatility Analysis (4-hour intervals, last 50 bars):\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "    for category, category_data in all_data.items():\n",
    "        print(f\"\\n{category}:\")\n",
    "        for symbol, data in category_data.items():\n",
    "            if len(data) > 1:\n",
    "                # Calculate price volatility (standard deviation of returns)\n",
    "                returns = []\n",
    "                for i in range(1, len(data)):\n",
    "                    ret = (data[i].close - data[i - 1].close) / data[i - 1].close\n",
    "                    returns.append(ret)\n",
    "\n",
    "                if returns:\n",
    "                    volatility = (\n",
    "                        sum((r - sum(returns) / len(returns)) ** 2 for r in returns)\n",
    "                        / len(returns)\n",
    "                    ) ** 0.5\n",
    "                    volatility_pct = volatility * 100\n",
    "\n",
    "                    print(\n",
    "                        f\"  {symbol:20} | Volatility: {volatility_pct:.3f}% | Latest: ${data[-1].close:.6f}\"\n",
    "                    )\n",
    "\n",
    "    return all_data\n",
    "\n",
    "\n",
    "# Fetch crypto and forex data\n",
    "crypto_forex_data = await fetch_crypto_and_forex_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fm6ipq6kth",
   "metadata": {},
   "source": [
    "## Real-time Data Streaming (Limited Demo)\n",
    "\n",
    "‚ö†Ô∏è **Note**: Real-time streaming is demonstrated with a limited time window to prevent infinite loops in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "qtiab9bamnn",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting limited real-time data stream (30 seconds)...\n",
      "Symbol: BINANCE:BTCUSDT (Bitcoin)\n",
      "--------------------------------------------------\n",
      "üìä Bar 1: 2025-07-30T06:54:00+00:00 | Close: $118,288.00 | Volume: 1\n",
      "üìä Bar 2: 2025-07-30T06:55:00+00:00 | Close: $118,307.81 | Volume: 5\n",
      "üìä Bar 3: 2025-07-30T06:56:00+00:00 | Close: $118,318.16 | Volume: 2\n",
      "üìä Bar 4: 2025-07-30T06:57:00+00:00 | Close: $118,318.16 | Volume: 2\n",
      "üìä Bar 5: 2025-07-30T06:58:00+00:00 | Close: $118,318.16 | Volume: 2\n",
      "üìä Bar 6: 2025-07-30T06:59:00+00:00 | Close: $118,287.31 | Volume: 7\n",
      "üìä Bar 7: 2025-07-30T07:00:00+00:00 | Close: $118,287.31 | Volume: 3\n",
      "üìä Bar 8: 2025-07-30T07:01:00+00:00 | Close: $118,306.00 | Volume: 7\n",
      "üìä Bar 9: 2025-07-30T07:02:00+00:00 | Close: $118,308.56 | Volume: 1\n",
      "üìä Bar 10: 2025-07-30T07:03:00+00:00 | Close: $118,311.72 | Volume: 1\n",
      "\n",
      "üìà Received 10 bars, stopping demo\n",
      "\n",
      "‚úÖ Real-time demo completed. Received 10 bars.\n"
     ]
    }
   ],
   "source": [
    "async def limited_realtime_demo():\n",
    "    \"\"\"Demonstrate real-time streaming with a time limit.\"\"\"\n",
    "\n",
    "    print(\"üöÄ Starting limited real-time data stream (30 seconds)...\")\n",
    "    print(\"Symbol: BINANCE:BTCUSDT (Bitcoin)\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    start_time = asyncio.get_event_loop().time()\n",
    "    timeout_seconds = 30  # Limit to 30 seconds\n",
    "    bar_count = 0\n",
    "\n",
    "    try:\n",
    "        async with OHLCV() as ohlcv:\n",
    "            async for bar in ohlcv.get_ohlcv(\"BINANCE:BTCUSDT\", interval=\"1\"):\n",
    "                # Check timeout\n",
    "                if asyncio.get_event_loop().time() - start_time > timeout_seconds:\n",
    "                    print(f\"\\n‚è∞ Demo timeout reached ({timeout_seconds}s)\")\n",
    "                    break\n",
    "\n",
    "                bar_count += 1\n",
    "                timestamp_str = convert_timestamp_to_iso(bar.timestamp)\n",
    "\n",
    "                print(\n",
    "                    f\"üìä Bar {bar_count}: {timestamp_str} | \"\n",
    "                    f\"Close: ${bar.close:,.2f} | \"\n",
    "                    f\"Volume: {bar.volume:,.0f}\"\n",
    "                )\n",
    "\n",
    "                # Also limit by number of bars\n",
    "                if bar_count >= 10:\n",
    "                    print(f\"\\nüìà Received {bar_count} bars, stopping demo\")\n",
    "                    break\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Streaming error: {e}\")\n",
    "\n",
    "    print(f\"\\n‚úÖ Real-time demo completed. Received {bar_count} bars.\")\n",
    "\n",
    "\n",
    "# Run limited real-time demo\n",
    "await limited_realtime_demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7uvmq7e7cfr",
   "metadata": {},
   "source": [
    "## Error Handling and Best Practices\n",
    "\n",
    "Demonstration of proper error handling and best practices when working with TVKit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "289vajx2k3t",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üõ°Ô∏è  Error Handling and Best Practices\n",
      "=============================================\n",
      "\n",
      "1Ô∏è‚É£  Invalid Symbol Handling:\n",
      "  üì• Attempting to fetch INVALID:SYMBOL...\n",
      "    ‚ùå Expected error: ValueError: Invalid exchange:symbol 'INVALID:SYMBOL' after 3 attempts\n",
      "  üì• Attempting to fetch BADEXCHANGE:BADSTOCK...\n",
      "    ‚ùå Expected error: ValueError: Invalid exchange:symbol 'BADEXCHANGE:BADSTOCK' after 3 attempts\n",
      "\n",
      "2Ô∏è‚É£  Connection Resilience:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-30 14:03:49,347 - ERROR - Failed to export OHLCV data to JSON: [Errno 30] Read-only file system: '/invalid'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ‚úÖ Successfully fetched 5 bars\n",
      "\n",
      "3Ô∏è‚É£  Export Error Handling:\n",
      "    ‚ùå Export failed: [Errno 30] Read-only file system: '/invalid'\n",
      "\n",
      "üí° Best Practices Summary:\n",
      "   ‚Ä¢ Always use async context managers (async with)\n",
      "   ‚Ä¢ Handle symbol validation errors gracefully\n",
      "   ‚Ä¢ Set appropriate timeouts for real-time streams\n",
      "   ‚Ä¢ Check export results for success status\n",
      "   ‚Ä¢ Use try-except blocks for robust error handling\n",
      "   ‚Ä¢ Validate data before processing\n"
     ]
    }
   ],
   "source": [
    "async def demonstrate_error_handling():\n",
    "    \"\"\"Show proper error handling techniques with TVKit.\"\"\"\n",
    "\n",
    "    print(\"üõ°Ô∏è  Error Handling and Best Practices\")\n",
    "    print(\"=\" * 45)\n",
    "\n",
    "    # 1. Handle invalid symbols gracefully\n",
    "    print(\"\\n1Ô∏è‚É£  Invalid Symbol Handling:\")\n",
    "    invalid_symbols = [\"INVALID:SYMBOL\", \"BADEXCHANGE:BADSTOCK\"]\n",
    "\n",
    "    async with OHLCV() as ohlcv:\n",
    "        for symbol in invalid_symbols:\n",
    "            try:\n",
    "                print(f\"  üì• Attempting to fetch {symbol}...\")\n",
    "                data = await ohlcv.get_historical_ohlcv(\n",
    "                    exchange_symbol=symbol, interval=\"1D\", bars_count=10\n",
    "                )\n",
    "                print(f\"    ‚úÖ Success: Got {len(data)} bars\")\n",
    "            except Exception as e:\n",
    "                print(f\"    ‚ùå Expected error: {type(e).__name__}: {e}\")\n",
    "\n",
    "    # 2. Handle network timeouts and connection issues\n",
    "    print(\"\\n2Ô∏è‚É£  Connection Resilience:\")\n",
    "\n",
    "    try:\n",
    "        async with OHLCV() as ohlcv:\n",
    "            # This should work normally\n",
    "            data = await ohlcv.get_historical_ohlcv(\n",
    "                exchange_symbol=\"NASDAQ:AAPL\", interval=\"1D\", bars_count=5\n",
    "            )\n",
    "            print(f\"    ‚úÖ Successfully fetched {len(data)} bars\")\n",
    "    except Exception as e:\n",
    "        print(f\"    ‚ùå Connection error: {e}\")\n",
    "\n",
    "    # 3. Export error handling\n",
    "    print(\"\\n3Ô∏è‚É£  Export Error Handling:\")\n",
    "\n",
    "    try:\n",
    "        exporter = DataExporter()\n",
    "\n",
    "        # Try to export to an invalid path\n",
    "        result = await exporter.export_ohlcv_data(\n",
    "            apple_data[:5],  # Use small subset\n",
    "            ExportFormat.JSON,\n",
    "            file_path=\"/invalid/path/cannot_write_here.json\",\n",
    "        )\n",
    "\n",
    "        if result.success:\n",
    "            print(\"    ‚úÖ Export successful\")\n",
    "        else:\n",
    "            print(f\"    ‚ùå Export failed: {result.error_message}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"    ‚ùå Export exception: {type(e).__name__}: {e}\")\n",
    "\n",
    "    # 4. Best practices summary\n",
    "    print(\"\\nüí° Best Practices Summary:\")\n",
    "    print(\"   ‚Ä¢ Always use async context managers (async with)\")\n",
    "    print(\"   ‚Ä¢ Handle symbol validation errors gracefully\")\n",
    "    print(\"   ‚Ä¢ Set appropriate timeouts for real-time streams\")\n",
    "    print(\"   ‚Ä¢ Check export results for success status\")\n",
    "    print(\"   ‚Ä¢ Use try-except blocks for robust error handling\")\n",
    "    print(\"   ‚Ä¢ Validate data before processing\")\n",
    "\n",
    "\n",
    "# Demonstrate error handling\n",
    "await demonstrate_error_handling()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qv3hky6ml6g",
   "metadata": {},
   "source": "## Summary\n\nThis notebook has demonstrated the comprehensive capabilities of TVKit:\n\n### ‚úÖ Completed Examples\n\n- **Basic OHLCV Data Fetching** - Retrieved historical market data for Apple stock\n- **Multi-format Data Export** - Exported to Polars DataFrame, JSON, and CSV formats\n- **Multi-symbol Operations** - Compared performance across multiple stocks\n- **Cryptocurrency & Forex** - Demonstrated support for various asset classes\n- **Macro Liquidity Indicators** - Accessed INDEX:NDFI and USI:PCC for quantitative analysis\n- **Quantitative Integration** - Showed integration with systematic trading models\n- **Real-time Streaming** - Limited demo of live data streaming\n- **Error Handling** - Best practices for robust applications\n\n### üîß Key Features Highlighted\n\n- **Async Architecture** - All operations use modern async/await patterns\n- **Type Safety** - Comprehensive Pydantic models for data validation\n- **Multiple Asset Classes** - Stocks, crypto, forex, and macro indicators\n- **Flexible Export System** - Support for Polars, JSON, CSV with custom options\n- **Real-time Capabilities** - WebSocket streaming for live market data\n- **Quantitative Analysis** - Tools for systematic trading and risk management\n- **Macro Indicators** - Access to essential liquidity and breadth metrics\n- **Error Resilience** - Robust error handling and validation\n\n### üìä Macro Indicators Covered\n\n- **INDEX:NDFI** - Net Demand For Income indicator for market breadth analysis\n- **USI:PCC** - Put/Call Ratio for sentiment and liquidity analysis\n- **Quantitative Integration** - Examples for systematic trading strategies\n- **Risk Management** - Regime detection and portfolio optimization\n\n### üìö Next Steps\n\n- Explore the full [TVKit documentation](https://github.com/your-repo/tvkit)\n- Check out additional examples in the `examples/` directory\n- Review the API reference for advanced features\n- Consider integrating TVKit into your financial analysis workflows\n- Implement macro indicators in your quantitative trading models\n\n**Happy Trading! üìà**"
  },
  {
   "cell_type": "markdown",
   "id": "a4dh98r3r6j",
   "metadata": {},
   "source": "## Macro Liquidity and Market Breadth Indicators\n\nThis section demonstrates accessing macro liquidity and market breadth indicators that are essential for quantitative liquidity models, macro regime detection, and systematic trading strategies.\n\n### Key Indicators Covered:\n- **INDEX:NDFI** - Net Demand For Income (Market Breadth Indicator)\n- **USI:PCC** - Put/Call Ratio (Liquidity and Sentiment Indicator)\n\nThese indicators are widely used in professional research for:\n- **Liquidity Regime Analysis** - Understanding market liquidity conditions\n- **Risk Management** - Macro trend detection and regime changes  \n- **Portfolio Optimization** - Systematic trading strategy development\n- **Market Timing** - Entry/exit signal generation"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ary01uidfj",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def fetch_macro_liquidity_indicators():\n",
    "    \"\"\"\n",
    "    Fetch macro liquidity and market breadth indicators.\n",
    "\n",
    "    These indicators are essential for:\n",
    "    - Macro liquidity regime detection\n",
    "    - Market breadth analysis\n",
    "    - Systematic trading strategies\n",
    "    - Risk management and portfolio optimization\n",
    "    \"\"\"\n",
    "\n",
    "    # Define macro indicators with descriptions\n",
    "    macro_indicators = {\n",
    "        \"INDEX:NDFI\": {\n",
    "            \"name\": \"Net Demand For Income\",\n",
    "            \"description\": \"Market breadth indicator measuring income-seeking demand\",\n",
    "            \"use_case\": \"Liquidity regime detection, macro trend analysis\",\n",
    "        },\n",
    "        \"USI:PCC\": {\n",
    "            \"name\": \"Put/Call Ratio\",\n",
    "            \"description\": \"Options sentiment and liquidity indicator\",\n",
    "            \"use_case\": \"Market sentiment, volatility prediction, contrarian signals\",\n",
    "        },\n",
    "    }\n",
    "\n",
    "    indicator_data = {}\n",
    "\n",
    "    print(\"üéØ Fetching Macro Liquidity and Market Breadth Indicators\")\n",
    "    print(\"=\" * 65)\n",
    "\n",
    "    async with OHLCV() as ohlcv:\n",
    "        for symbol, info in macro_indicators.items():\n",
    "            try:\n",
    "                print(f\"\\nüìä Fetching {info['name']} ({symbol})...\")\n",
    "                print(f\"   üìù Description: {info['description']}\")\n",
    "                print(f\"   üéØ Use Case: {info['use_case']}\")\n",
    "\n",
    "                # Fetch historical data - using daily intervals for macro analysis\n",
    "                data = await ohlcv.get_historical_ohlcv(\n",
    "                    exchange_symbol=symbol,\n",
    "                    interval=\"1D\",  # Daily data for macro analysis\n",
    "                    bars_count=100,  # ~3-4 months of data\n",
    "                )\n",
    "\n",
    "                indicator_data[symbol] = {\"data\": data, \"info\": info}\n",
    "\n",
    "                # Display latest values and basic statistics\n",
    "                if data:\n",
    "                    latest = data[-1]\n",
    "                    earliest = data[0]\n",
    "\n",
    "                    # Calculate some basic statistics\n",
    "                    values = [bar.close for bar in data]\n",
    "                    avg_value = sum(values) / len(values)\n",
    "                    max_value = max(values)\n",
    "                    min_value = min(values)\n",
    "\n",
    "                    # Calculate volatility (standard deviation)\n",
    "                    variance = sum((x - avg_value) ** 2 for x in values) / len(values)\n",
    "                    volatility = variance**0.5\n",
    "\n",
    "                    print(f\"   ‚úÖ Successfully fetched {len(data)} bars\")\n",
    "                    print(\n",
    "                        f\"   üìÖ Data range: {convert_timestamp_to_iso(earliest.timestamp)[:10]} to {convert_timestamp_to_iso(latest.timestamp)[:10]}\"\n",
    "                    )\n",
    "                    print(f\"   üìà Latest value: {latest.close:.6f}\")\n",
    "                    print(\n",
    "                        f\"   üìä Statistics: Min={min_value:.6f}, Max={max_value:.6f}, Avg={avg_value:.6f}\"\n",
    "                    )\n",
    "                    print(f\"   üìâ Volatility: {volatility:.6f}\")\n",
    "\n",
    "                else:\n",
    "                    print(\"   ‚ùå No data received\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"   ‚ùå Error fetching {symbol}: {type(e).__name__}: {e}\")\n",
    "                indicator_data[symbol] = {\"error\": str(e), \"info\": info}\n",
    "\n",
    "    return indicator_data\n",
    "\n",
    "\n",
    "# Fetch macro indicators\n",
    "macro_data = await fetch_macro_liquidity_indicators()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fnww9frr3su",
   "metadata": {},
   "source": "### Macro Indicator Analysis and Export\n\nExport the macro indicators to various formats for further analysis and integrate them with quantitative models."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "l9v0gu5ama",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def analyze_and_export_macro_indicators(macro_data):\n",
    "    \"\"\"\n",
    "    Analyze macro indicators and export to multiple formats.\n",
    "\n",
    "    This demonstrates how to:\n",
    "    - Process macro liquidity indicators for quantitative analysis\n",
    "    - Export data for integration with systematic trading models\n",
    "    - Calculate key metrics for liquidity regime detection\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"üî¨ Analyzing Macro Indicators for Quantitative Models\")\n",
    "    print(\"=\" * 55)\n",
    "\n",
    "    exporter = DataExporter()\n",
    "    analysis_results = {}\n",
    "\n",
    "    for symbol, indicator_info in macro_data.items():\n",
    "        if \"error\" in indicator_info:\n",
    "            print(f\"\\n‚ùå Skipping {symbol} due to error: {indicator_info['error']}\")\n",
    "            continue\n",
    "\n",
    "        data = indicator_info[\"data\"]\n",
    "        info = indicator_info[\"info\"]\n",
    "\n",
    "        if not data:\n",
    "            print(f\"\\n‚ùå No data available for {symbol}\")\n",
    "            continue\n",
    "\n",
    "        print(f\"\\nüìä Analyzing {info['name']} ({symbol})\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "        # Convert to DataFrame for analysis\n",
    "        df = await exporter.to_polars(data, add_analysis=True)\n",
    "        print(f\"   üìà DataFrame shape: {df.shape}\")\n",
    "\n",
    "        # Calculate additional metrics for macro analysis\n",
    "        if len(data) > 20:  # Ensure sufficient data\n",
    "            # Recent vs Historical comparison (last 20 days vs previous 20)\n",
    "            recent_values = [bar.close for bar in data[-20:]]\n",
    "            historical_values = (\n",
    "                [bar.close for bar in data[-40:-20]]\n",
    "                if len(data) >= 40\n",
    "                else [bar.close for bar in data[:-20]]\n",
    "            )\n",
    "\n",
    "            recent_avg = sum(recent_values) / len(recent_values)\n",
    "            historical_avg = (\n",
    "                sum(historical_values) / len(historical_values)\n",
    "                if historical_values\n",
    "                else recent_avg\n",
    "            )\n",
    "\n",
    "            # Trend analysis\n",
    "            trend_change = (\n",
    "                ((recent_avg - historical_avg) / historical_avg * 100)\n",
    "                if historical_avg != 0\n",
    "                else 0\n",
    "            )\n",
    "\n",
    "            # Volatility analysis\n",
    "            recent_volatility = (\n",
    "                sum((x - recent_avg) ** 2 for x in recent_values) / len(recent_values)\n",
    "            ) ** 0.5\n",
    "\n",
    "            # Percentile analysis (current position relative to historical range)\n",
    "            all_values = [bar.close for bar in data]\n",
    "            current_value = data[-1].close\n",
    "            sorted_values = sorted(all_values)\n",
    "            percentile = (\n",
    "                sum(1 for v in sorted_values if v <= current_value) / len(sorted_values)\n",
    "            ) * 100\n",
    "\n",
    "            analysis_results[symbol] = {\n",
    "                \"name\": info[\"name\"],\n",
    "                \"current_value\": current_value,\n",
    "                \"recent_avg\": recent_avg,\n",
    "                \"historical_avg\": historical_avg,\n",
    "                \"trend_change_pct\": trend_change,\n",
    "                \"volatility\": recent_volatility,\n",
    "                \"percentile\": percentile,\n",
    "                \"use_case\": info[\"use_case\"],\n",
    "            }\n",
    "\n",
    "            print(f\"   üìà Current Value: {current_value:.6f}\")\n",
    "            print(f\"   üìä Recent Avg (20d): {recent_avg:.6f}\")\n",
    "            print(f\"   üìä Historical Avg: {historical_avg:.6f}\")\n",
    "            print(f\"   üìà Trend Change: {trend_change:+.2f}%\")\n",
    "            print(f\"   üìâ Recent Volatility: {recent_volatility:.6f}\")\n",
    "            print(f\"   üìä Current Percentile: {percentile:.1f}%\")\n",
    "\n",
    "            # Interpretation for trading strategies\n",
    "            if symbol == \"INDEX:NDFI\":\n",
    "                if percentile > 75:\n",
    "                    signal = \"High income demand - Potential market strength\"\n",
    "                elif percentile < 25:\n",
    "                    signal = \"Low income demand - Potential market weakness\"\n",
    "                else:\n",
    "                    signal = \"Neutral income demand\"\n",
    "                print(f\"   üéØ Signal: {signal}\")\n",
    "\n",
    "            elif symbol == \"USI:PCC\":\n",
    "                if percentile > 75:\n",
    "                    signal = \"High put/call ratio - Potential contrarian bullish signal\"\n",
    "                elif percentile < 25:\n",
    "                    signal = \"Low put/call ratio - Potential market complacency\"\n",
    "                else:\n",
    "                    signal = \"Neutral sentiment\"\n",
    "                print(f\"   üéØ Signal: {signal}\")\n",
    "\n",
    "        # Export individual indicator data\n",
    "        try:\n",
    "            # Export to CSV for systematic trading models\n",
    "            csv_path = await exporter.to_csv(\n",
    "                data,\n",
    "                f\"./tvkit_exports/macro_{symbol.replace(':', '_').lower()}_data.csv\",\n",
    "                include_metadata=True,\n",
    "                timestamp_format=\"iso\",\n",
    "            )\n",
    "            print(f\"   üíæ Exported to CSV: {csv_path}\")\n",
    "\n",
    "            # Export to JSON for web applications\n",
    "            json_path = await exporter.to_json(\n",
    "                data,\n",
    "                f\"./tvkit_exports/macro_{symbol.replace(':', '_').lower()}_data.json\",\n",
    "                include_metadata=True,\n",
    "                indent=2,\n",
    "            )\n",
    "            print(f\"   üíæ Exported to JSON: {json_path}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ùå Export error: {e}\")\n",
    "\n",
    "    # Summary analysis\n",
    "    print(\"\\nüéØ Macro Liquidity Analysis Summary\")\n",
    "    print(\"=\" * 40)\n",
    "\n",
    "    for symbol, analysis in analysis_results.items():\n",
    "        print(f\"\\n{analysis['name']} ({symbol}):\")\n",
    "        print(f\"  Current Level: {analysis['percentile']:.1f}th percentile\")\n",
    "        print(f\"  Trend: {analysis['trend_change_pct']:+.2f}% (recent vs historical)\")\n",
    "        print(f\"  Use in Models: {analysis['use_case']}\")\n",
    "\n",
    "    return analysis_results\n",
    "\n",
    "\n",
    "# Analyze and export macro indicators\n",
    "if macro_data:\n",
    "    macro_analysis = await analyze_and_export_macro_indicators(macro_data)\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No macro data available for analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lmc1azjj0fg",
   "metadata": {},
   "source": "### Integration with Quantitative Models\n\nThis section shows how to integrate macro indicators with quantitative trading strategies and risk management frameworks."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ujo4vfpo1g",
   "metadata": {},
   "outputs": [],
   "source": [
    "def demonstrate_quantitative_integration(macro_analysis):\n",
    "    \"\"\"\n",
    "    Demonstrate how to integrate macro indicators into quantitative models.\n",
    "\n",
    "    This shows practical applications for:\n",
    "    - Systematic trading strategies\n",
    "    - Risk regime detection\n",
    "    - Portfolio allocation models\n",
    "    - Market timing systems\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"üßÆ Quantitative Model Integration Examples\")\n",
    "    print(\"=\" * 45)\n",
    "\n",
    "    if not macro_analysis:\n",
    "        print(\"‚ö†Ô∏è No macro analysis data available for integration examples\")\n",
    "        return\n",
    "\n",
    "    # Example 1: Liquidity Regime Classification\n",
    "    print(\"\\n1Ô∏è‚É£ Liquidity Regime Classification\")\n",
    "    print(\"-\" * 35)\n",
    "\n",
    "    for symbol, analysis in macro_analysis.items():\n",
    "        regime = \"UNKNOWN\"\n",
    "        confidence = 0\n",
    "\n",
    "        if symbol == \"INDEX:NDFI\":\n",
    "            # NDFI-based liquidity regime detection\n",
    "            percentile = analysis[\"percentile\"]\n",
    "            trend = analysis[\"trend_change_pct\"]\n",
    "\n",
    "            if percentile > 75 and trend > 0:\n",
    "                regime = \"HIGH_LIQUIDITY_EXPANDING\"\n",
    "                confidence = 0.85\n",
    "            elif percentile > 60:\n",
    "                regime = \"HIGH_LIQUIDITY_STABLE\"\n",
    "                confidence = 0.70\n",
    "            elif percentile < 25 and trend < 0:\n",
    "                regime = \"LOW_LIQUIDITY_CONTRACTING\"\n",
    "                confidence = 0.80\n",
    "            elif percentile < 40:\n",
    "                regime = \"LOW_LIQUIDITY_STABLE\"\n",
    "                confidence = 0.65\n",
    "            else:\n",
    "                regime = \"NEUTRAL_LIQUIDITY\"\n",
    "                confidence = 0.50\n",
    "\n",
    "        elif symbol == \"USI:PCC\":\n",
    "            # Put/Call ratio sentiment analysis\n",
    "            percentile = analysis[\"percentile\"]\n",
    "\n",
    "            if percentile > 80:\n",
    "                regime = \"EXTREME_FEAR\"\n",
    "                confidence = 0.85\n",
    "            elif percentile > 60:\n",
    "                regime = \"ELEVATED_FEAR\"\n",
    "                confidence = 0.70\n",
    "            elif percentile < 20:\n",
    "                regime = \"EXTREME_COMPLACENCY\"\n",
    "                confidence = 0.85\n",
    "            elif percentile < 40:\n",
    "                regime = \"LOW_FEAR\"\n",
    "                confidence = 0.70\n",
    "            else:\n",
    "                regime = \"NEUTRAL_SENTIMENT\"\n",
    "                confidence = 0.50\n",
    "\n",
    "        print(f\"   {analysis['name']} ({symbol}):\")\n",
    "        print(f\"   üìä Regime: {regime}\")\n",
    "        print(f\"   üéØ Confidence: {confidence:.1%}\")\n",
    "        print(f\"   üìà Current Level: {analysis['percentile']:.1f}th percentile\")\n",
    "\n",
    "    # Example 2: Risk Management Signals\n",
    "    print(\"\\n2Ô∏è‚É£ Risk Management Framework\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "    # Combine indicators for risk assessment\n",
    "    risk_score = 0\n",
    "    signal_count = 0\n",
    "\n",
    "    for symbol, analysis in macro_analysis.items():\n",
    "        if symbol == \"INDEX:NDFI\":\n",
    "            # Low NDFI = higher risk\n",
    "            if analysis[\"percentile\"] < 25:\n",
    "                risk_score += 2\n",
    "            elif analysis[\"percentile\"] < 50:\n",
    "                risk_score += 1\n",
    "            signal_count += 1\n",
    "\n",
    "        elif symbol == \"USI:PCC\":\n",
    "            # Extreme levels indicate higher volatility risk\n",
    "            if analysis[\"percentile\"] > 75 or analysis[\"percentile\"] < 25:\n",
    "                risk_score += 1\n",
    "            signal_count += 1\n",
    "\n",
    "    if signal_count > 0:\n",
    "        avg_risk = risk_score / signal_count\n",
    "\n",
    "        if avg_risk >= 1.5:\n",
    "            risk_level = \"HIGH\"\n",
    "            portfolio_action = \"Reduce position sizes, increase cash allocation\"\n",
    "        elif avg_risk >= 0.75:\n",
    "            risk_level = \"MEDIUM\"\n",
    "            portfolio_action = \"Moderate position sizing, maintain diversification\"\n",
    "        else:\n",
    "            risk_level = \"LOW\"\n",
    "            portfolio_action = \"Normal position sizing, consider growth allocation\"\n",
    "\n",
    "        print(\n",
    "            f\"   üìä Combined Risk Score: {risk_score}/{signal_count * 2} ({avg_risk:.2f})\"\n",
    "        )\n",
    "        print(f\"   ‚ö†Ô∏è Risk Level: {risk_level}\")\n",
    "        print(f\"   üéØ Suggested Action: {portfolio_action}\")\n",
    "\n",
    "    # Example 3: Signal Generation for Trading\n",
    "    print(\"\\n3Ô∏è‚É£ Trading Signal Generation\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "    signals = []\n",
    "\n",
    "    for symbol, analysis in macro_analysis.items():\n",
    "        if symbol == \"INDEX:NDFI\":\n",
    "            if analysis[\"percentile\"] < 25 and analysis[\"trend_change_pct\"] > 5:\n",
    "                signals.append(\"NDFI Reversal: Potential bullish divergence\")\n",
    "            elif analysis[\"percentile\"] > 75 and analysis[\"trend_change_pct\"] < -5:\n",
    "                signals.append(\"NDFI Peak: Potential bearish reversal\")\n",
    "\n",
    "        elif symbol == \"USI:PCC\":\n",
    "            if analysis[\"percentile\"] > 80:\n",
    "                signals.append(\"PCC Extreme Fear: Contrarian bullish opportunity\")\n",
    "            elif analysis[\"percentile\"] < 20:\n",
    "                signals.append(\"PCC Complacency: Monitor for volatility increase\")\n",
    "\n",
    "    if signals:\n",
    "        for i, signal in enumerate(signals, 1):\n",
    "            print(f\"   {i}. {signal}\")\n",
    "    else:\n",
    "        print(\"   üìä No clear trading signals detected\")\n",
    "\n",
    "    # Example 4: Model Integration Code Template\n",
    "    print(\"\\n4Ô∏è‚É£ Code Template for Systematic Models\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "    template = '''\n",
    "# Example integration with systematic trading model\n",
    "def update_model_with_macro_indicators(macro_data):\n",
    "    \"\"\"\n",
    "    Template for integrating macro indicators into systematic models.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Extract indicator values\n",
    "    ndfi_percentile = macro_data.get(\"INDEX:NDFI\", {}).get(\"percentile\", 50)\n",
    "    pcc_percentile = macro_data.get(\"USI:PCC\", {}).get(\"percentile\", 50)\n",
    "    \n",
    "    # Regime detection logic\n",
    "    liquidity_regime = classify_liquidity_regime(ndfi_percentile)\n",
    "    sentiment_regime = classify_sentiment_regime(pcc_percentile)\n",
    "    \n",
    "    # Adjust model parameters based on regime\n",
    "    if liquidity_regime == \"LOW_LIQUIDITY\":\n",
    "        position_sizing_multiplier = 0.5  # Reduce positions\n",
    "        volatility_target = 0.10  # Lower vol target\n",
    "    else:\n",
    "        position_sizing_multiplier = 1.0\n",
    "        volatility_target = 0.15\n",
    "    \n",
    "    return {\n",
    "        \"position_sizing\": position_sizing_multiplier,\n",
    "        \"volatility_target\": volatility_target,\n",
    "        \"regime_signals\": [liquidity_regime, sentiment_regime]\n",
    "    }\n",
    "    '''\n",
    "\n",
    "    print(template)\n",
    "\n",
    "    return {\n",
    "        \"risk_assessment\": {\n",
    "            \"risk_score\": risk_score if \"risk_score\" in locals() else 0,\n",
    "            \"risk_level\": risk_level if \"risk_level\" in locals() else \"UNKNOWN\",\n",
    "        },\n",
    "        \"trading_signals\": signals,\n",
    "        \"regime_classification\": {\n",
    "            symbol: regime for symbol, analysis in macro_analysis.items()\n",
    "        },\n",
    "    }\n",
    "\n",
    "\n",
    "# Run quantitative integration examples\n",
    "if \"macro_analysis\" in locals() and macro_analysis:\n",
    "    quant_results = demonstrate_quantitative_integration(macro_analysis)\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Running integration examples with sample data...\")\n",
    "    # Provide example for demonstration\n",
    "    sample_analysis = {\n",
    "        \"INDEX:NDFI\": {\n",
    "            \"name\": \"Net Demand For Income\",\n",
    "            \"percentile\": 65.0,\n",
    "            \"trend_change_pct\": 2.5,\n",
    "        },\n",
    "        \"USI:PCC\": {\n",
    "            \"name\": \"Put/Call Ratio\",\n",
    "            \"percentile\": 75.0,\n",
    "            \"trend_change_pct\": -1.2,\n",
    "        },\n",
    "    }\n",
    "    quant_results = demonstrate_quantitative_integration(sample_analysis)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}