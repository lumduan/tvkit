{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d461b920",
   "metadata": {},
   "source": [
    "# TVKit Comprehensive Sample Notebook\n",
    "\n",
    "**TVKit** is a Python library for TradingView's financial data APIs with real-time WebSocket streaming and comprehensive data export capabilities.\n",
    "\n",
    "## Features Covered in This Notebook\n",
    "\n",
    "- **OHLCV Data Fetching** - Historical and real-time financial data\n",
    "- **Data Export System** - Multiple formats (Polars DataFrame, JSON, CSV)\n",
    "- **Financial Analysis** - Technical indicators and data analysis\n",
    "- **Real-time Streaming** - Live market data updates\n",
    "- **Multi-symbol Operations** - Working with multiple financial instruments\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "```bash\n",
    "# Install tvkit with all dependencies\n",
    "pip install tvkit polars matplotlib seaborn\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e7a8b27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Analysis libraries loaded successfully\n",
      "ðŸš€ TVKit sample notebook initialized!\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "\n",
    "# TVKit imports\n",
    "from tvkit.api.chart.ohlcv import OHLCV\n",
    "from tvkit.export import DataExporter, ExportFormat\n",
    "from tvkit.api.utils import convert_timestamp_to_iso\n",
    "\n",
    "# Enable nested event loops for Jupyter notebooks\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Optional: Data analysis and visualization\n",
    "try:\n",
    "    import polars as pl\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "\n",
    "    ANALYSIS_AVAILABLE = True\n",
    "    print(\"âœ… Analysis libraries loaded successfully\")\n",
    "\n",
    "    # Use the imports to avoid F401 warnings\n",
    "    _ = pl, plt, sns\n",
    "except ImportError as e:\n",
    "    ANALYSIS_AVAILABLE = False\n",
    "    print(f\"âš ï¸  Analysis libraries not available: {e}\")\n",
    "\n",
    "print(\"ðŸš€ TVKit sample notebook initialized!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aba7236",
   "metadata": {},
   "source": [
    "```markdown\n",
    "## Logging Configuration\n",
    "\n",
    "The following cell configures logging and warning settings to ensure clean, readable notebook output:\n",
    "\n",
    "- **Suppresses debug and info logs** from libraries such as `httpx`, `websockets`, and others, so only warnings and errors are shown.\n",
    "- **Disables most warnings** to avoid cluttering the notebook with non-critical messages.\n",
    "- This setup is recommended for interactive analysis, as it keeps the output focused on results and important issues.\n",
    "\n",
    "You can adjust the logging level or re-enable warnings if you need more detailed troubleshooting information.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3423a685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”‡ Debug logging disabled - clean output mode enabled\n"
     ]
    }
   ],
   "source": [
    "# Configure logging to suppress debug messages\n",
    "import logging\n",
    "import warnings\n",
    "\n",
    "# Set logging levels to reduce verbosity\n",
    "logging.getLogger().setLevel(logging.WARNING)\n",
    "logging.getLogger(\"httpcore\").setLevel(logging.WARNING)\n",
    "logging.getLogger(\"httpx\").setLevel(logging.WARNING)\n",
    "logging.getLogger(\"websockets\").setLevel(logging.WARNING)\n",
    "\n",
    "# Optionally suppress warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "print(\"ðŸ”‡ Debug logging disabled - clean output mode enabled\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ye1cco9abvl",
   "metadata": {},
   "source": [
    "## Basic OHLCV Data Fetching\n",
    "\n",
    "Let's start by fetching historical OHLCV (Open, High, Low, Close, Volume) data for Apple stock (AAPL) from NASDAQ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "os2zfplyv28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Fetched 100 OHLCV bars\n",
      "ðŸ“… Date range: 2025-05-06T13:30:00+00:00 to 2025-09-26T13:30:00+00:00\n",
      "\n",
      "ðŸ” First 3 bars:\n",
      "  Bar 1: 2025-05-06 - Close: $198.51, Volume: 51,216,482\n",
      "  Bar 2: 2025-05-07 - Close: $196.25, Volume: 68,616,943\n",
      "  Bar 3: 2025-05-08 - Close: $197.49, Volume: 50,478,872\n"
     ]
    }
   ],
   "source": [
    "async def fetch_historical_ohlcv_data():\n",
    "    \"\"\"Fetch historical OHLCV data for Apple stock.\"\"\"\n",
    "    async with OHLCV() as ohlcv:\n",
    "        # Fetch last 100 daily bars for Apple\n",
    "        ohlcv_data = await ohlcv.get_historical_ohlcv(\n",
    "            exchange_symbol=\"NASDAQ:AAPL\",\n",
    "            interval=\"1D\",  # Daily intervals\n",
    "            bars_count=100,\n",
    "        )\n",
    "\n",
    "    # Display basic information\n",
    "    print(f\"ðŸ“Š Fetched {len(ohlcv_data)} OHLCV bars\")\n",
    "    print(\n",
    "        f\"ðŸ“… Date range: {convert_timestamp_to_iso(ohlcv_data[0].timestamp)} to {convert_timestamp_to_iso(ohlcv_data[-1].timestamp)}\"\n",
    "    )\n",
    "\n",
    "    # Show first few bars\n",
    "    print(\"\\nðŸ” First 3 bars:\")\n",
    "    for i, bar in enumerate(ohlcv_data[:3]):\n",
    "        print(\n",
    "            f\"  Bar {i + 1}: {convert_timestamp_to_iso(bar.timestamp)[:10]} - Close: ${bar.close:.2f}, Volume: {bar.volume:,.0f}\"\n",
    "        )\n",
    "\n",
    "    return ohlcv_data\n",
    "\n",
    "\n",
    "# Run the function\n",
    "apple_data = await fetch_historical_ohlcv_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ctfisdz8tkq",
   "metadata": {},
   "source": [
    "## Data Export to Different Formats\n",
    "\n",
    "TVKit's `DataExporter` class provides seamless export to multiple formats including Polars DataFrames, JSON, and CSV files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "176h9cqcix4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“ˆ Exporting to Polars DataFrame ...\n",
      "DataFrame shape: (100, 6)\n",
      "Columns: ['timestamp', 'open', 'high', 'low', 'close', 'volume']\n",
      "\n",
      "ðŸ“‹ First 5 rows:\n",
      "shape: (5, 6)\n",
      "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚ timestamp           â”† open   â”† high     â”† low      â”† close  â”† volume      â”‚\n",
      "â”‚ ---                 â”† ---    â”† ---      â”† ---      â”† ---    â”† ---         â”‚\n",
      "â”‚ str                 â”† f64    â”† f64      â”† f64      â”† f64    â”† f64         â”‚\n",
      "â•žâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•¡\n",
      "â”‚ 2025-05-06T20:30:00 â”† 198.21 â”† 200.65   â”† 197.02   â”† 198.51 â”† 5.1216482e7 â”‚\n",
      "â”‚ 2025-05-07T20:30:00 â”† 199.17 â”† 199.44   â”† 193.25   â”† 196.25 â”† 6.8616943e7 â”‚\n",
      "â”‚ 2025-05-08T20:30:00 â”† 197.72 â”† 200.05   â”† 194.6796 â”† 197.49 â”† 5.0478872e7 â”‚\n",
      "â”‚ 2025-05-09T20:30:00 â”† 199.0  â”† 200.5399 â”† 197.535  â”† 198.53 â”† 3.6453923e7 â”‚\n",
      "â”‚ 2025-05-12T20:30:00 â”† 210.97 â”† 211.2679 â”† 206.75   â”† 210.79 â”† 6.3775814e7 â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
      "\n",
      "ðŸ’¾ Exporting to JSON file...\n",
      "JSON exported to: tvkit_exports/apple_ohlcv_data.json\n",
      "\n",
      "ðŸ“Š Exporting to CSV file...\n",
      "CSV exported to: tvkit_exports/apple_ohlcv_data.csv\n"
     ]
    }
   ],
   "source": [
    "async def demonstrate_data_export():\n",
    "    \"\"\"Demonstrate different data export formats.\"\"\"\n",
    "    exporter = DataExporter()\n",
    "\n",
    "    # 1. Export to Polars DataFrame\n",
    "    print(\"ðŸ“ˆ Exporting to Polars DataFrame ...\")\n",
    "    df = await exporter.to_polars(apple_data, add_analysis=False)\n",
    "\n",
    "    print(f\"DataFrame shape: {df.shape}\")\n",
    "    print(f\"Columns: {df.columns}\")\n",
    "    print(\"\\nðŸ“‹ First 5 rows:\")\n",
    "    print(df.head())\n",
    "\n",
    "    # 2. Export to JSON file\n",
    "    print(\"\\nðŸ’¾ Exporting to JSON file...\")\n",
    "    json_path = await exporter.to_json(\n",
    "        apple_data,\n",
    "        \"./tvkit_exports/apple_ohlcv_data.json\",\n",
    "        include_metadata=True,\n",
    "        indent=2,\n",
    "    )\n",
    "    print(f\"JSON exported to: {json_path}\")\n",
    "\n",
    "    # 3. Export to CSV file\n",
    "    print(\"\\nðŸ“Š Exporting to CSV file...\")\n",
    "    csv_path = await exporter.to_csv(\n",
    "        apple_data,\n",
    "        \"./tvkit_exports/apple_ohlcv_data.csv\",\n",
    "        include_metadata=True,\n",
    "        timestamp_format=\"iso\",\n",
    "    )\n",
    "    print(f\"CSV exported to: {csv_path}\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# Print Out of DataFrame\n",
    "df = await demonstrate_data_export()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hzfsd4vmgld",
   "metadata": {},
   "source": [
    "## Multi-Symbol Data Comparison\n",
    "\n",
    "Let's fetch data for multiple symbols and compare their performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "rkcencgahk8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Fetching data for multiple symbols...\n",
      "  ðŸ“¥ Fetching NASDAQ:AAPL...\n",
      "    âœ… Got 30 bars\n",
      "  ðŸ“¥ Fetching NASDAQ:GOOGL...\n",
      "    âœ… Got 30 bars\n",
      "  ðŸ“¥ Fetching NASDAQ:MSFT...\n",
      "    âœ… Got 30 bars\n",
      "  ðŸ“¥ Fetching NYSE:TSLA...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-27 10:46:39,674 - ERROR - Series error received from TradingView during historical data fetch\n",
      "2025-09-27 10:46:39,676 - ERROR - Error details: {'m': 'series_error', 'p': ['cs_fwlkrgsjqjpo', 'sds_1', 's1', 'resolve error', 'hon1-charts-free-3-tvbs-xkye6-1@hon1-charts-free-3-tvbs-xkye6-1'], 't': 1758944799, 't_ms': 1758944799774}\n",
      "2025-09-27 10:46:39,677 - ERROR - Please check the interval - this timeframe may not be supported for the symbol\n",
      "2025-09-27 10:46:39,678 - ERROR - Also verify that bars_count is within valid range\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    âŒ Failed to fetch NYSE:TSLA: No historical data received for symbol NYSE:TSLA\n",
      "\n",
      "ðŸ“Š Performance Summary (30-day period):\n",
      "------------------------------------------------------------\n",
      "NASDAQ:AAPL  | Change: +10.31% | Range: $223.78-$257.60 | Avg Vol: 54,343,191\n",
      "NASDAQ:GOOGL | Change: +20.91% | Range: $196.59-$256.00 | Avg Vol: 36,165,815\n",
      "NASDAQ:MSFT  | Change:  -1.67% | Range: $492.37-$526.10 | Avg Vol: 21,211,807\n"
     ]
    }
   ],
   "source": [
    "async def compare_multiple_symbols():\n",
    "    \"\"\"Fetch and compare data for multiple symbols.\"\"\"\n",
    "    symbols = [\n",
    "        \"NASDAQ:AAPL\",  # Apple\n",
    "        \"NASDAQ:GOOGL\",  # Google\n",
    "        \"NASDAQ:MSFT\",  # Microsoft\n",
    "        \"NYSE:TSLA\",  # Tesla\n",
    "    ]\n",
    "\n",
    "    symbol_data = {}\n",
    "\n",
    "    print(\"ðŸ”„ Fetching data for multiple symbols...\")\n",
    "\n",
    "    async with OHLCV() as ohlcv:\n",
    "        for symbol in symbols:\n",
    "            try:\n",
    "                print(f\"  ðŸ“¥ Fetching {symbol}...\")\n",
    "                data = await ohlcv.get_historical_ohlcv(\n",
    "                    exchange_symbol=symbol,\n",
    "                    interval=\"1D\",\n",
    "                    bars_count=30,  # Last 30 days\n",
    "                )\n",
    "                symbol_data[symbol] = data\n",
    "                print(f\"    âœ… Got {len(data)} bars\")\n",
    "            except Exception as e:\n",
    "                print(f\"    âŒ Failed to fetch {symbol}: {e}\")\n",
    "\n",
    "    # Calculate performance metrics\n",
    "    print(\"\\nðŸ“Š Performance Summary (30-day period):\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "    for symbol, data in symbol_data.items():\n",
    "        if len(data) >= 2:\n",
    "            first_close = data[0].close\n",
    "            last_close = data[-1].close\n",
    "            change_pct = ((last_close - first_close) / first_close) * 100\n",
    "\n",
    "            avg_volume = sum(bar.volume for bar in data) / len(data)\n",
    "            max_high = max(bar.high for bar in data)\n",
    "            min_low = min(bar.low for bar in data)\n",
    "\n",
    "            print(\n",
    "                f\"{symbol:12} | Change: {change_pct:+6.2f}% | \"\n",
    "                f\"Range: ${min_low:.2f}-${max_high:.2f} | \"\n",
    "                f\"Avg Vol: {avg_volume:,.0f}\"\n",
    "            )\n",
    "\n",
    "    return symbol_data\n",
    "\n",
    "\n",
    "# Run multi-symbol comparison\n",
    "multi_symbol_data = await compare_multiple_symbols()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7hgnqfh186s",
   "metadata": {},
   "source": [
    "## Cryptocurrency and Forex Data\n",
    "\n",
    "TVKit supports various asset classes including cryptocurrencies and forex pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "uk9l107cma",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š Fetching Cryptocurrency Data:\n",
      "----------------------------------------\n",
      "  ðŸ“¥ BINANCE:BTCUSDT...\n",
      "    âœ… Latest: $109629.810000 (Vol: 981)\n",
      "  ðŸ“¥ BINANCE:ETHUSDT...\n",
      "    âœ… Latest: $4025.800000 (Vol: 26,832)\n",
      "  ðŸ“¥ BINANCE:ADAUSDT...\n",
      "    âœ… Latest: $0.793800 (Vol: 5,371,120)\n",
      "\n",
      "ðŸ“Š Fetching Forex Data:\n",
      "----------------------------------------\n",
      "  ðŸ“¥ FX_IDC:EURUSD...\n",
      "    âœ… Latest: $1.170050 (Vol: 74,522)\n",
      "  ðŸ“¥ FX_IDC:GBPUSD...\n",
      "    âœ… Latest: $1.339900 (Vol: 87,029)\n",
      "  ðŸ“¥ FX_IDC:USDJPY...\n",
      "    âœ… Latest: $149.454000 (Vol: 107,252)\n",
      "\n",
      "ðŸ“ˆ Volatility Analysis (4-hour intervals, last 50 bars):\n",
      "------------------------------------------------------------\n",
      "\n",
      "Cryptocurrency:\n",
      "  BINANCE:BTCUSDT      | Volatility: 0.526% | Latest: $109629.810000\n",
      "  BINANCE:ETHUSDT      | Volatility: 0.987% | Latest: $4025.800000\n",
      "  BINANCE:ADAUSDT      | Volatility: 1.240% | Latest: $0.793800\n",
      "\n",
      "Forex:\n",
      "  FX_IDC:EURUSD        | Volatility: 0.168% | Latest: $1.170050\n",
      "  FX_IDC:GBPUSD        | Volatility: 0.179% | Latest: $1.339900\n",
      "  FX_IDC:USDJPY        | Volatility: 0.168% | Latest: $149.454000\n"
     ]
    }
   ],
   "source": [
    "async def fetch_crypto_and_forex_data():\n",
    "    \"\"\"Demonstrate fetching cryptocurrency and forex data.\"\"\"\n",
    "\n",
    "    # Different asset classes\n",
    "    symbols = {\n",
    "        \"Cryptocurrency\": [\n",
    "            \"BINANCE:BTCUSDT\",  # Bitcoin\n",
    "            \"BINANCE:ETHUSDT\",  # Ethereum\n",
    "            \"BINANCE:ADAUSDT\",  # Cardano\n",
    "        ],\n",
    "        \"Forex\": [\n",
    "            \"FX_IDC:EURUSD\",  # EUR/USD\n",
    "            \"FX_IDC:GBPUSD\",  # GBP/USD\n",
    "            \"FX_IDC:USDJPY\",  # USD/JPY\n",
    "        ],\n",
    "    }\n",
    "\n",
    "    all_data = {}\n",
    "\n",
    "    async with OHLCV() as ohlcv:\n",
    "        for category, symbol_list in symbols.items():\n",
    "            print(f\"\\nðŸ“Š Fetching {category} Data:\")\n",
    "            print(\"-\" * 40)\n",
    "\n",
    "            category_data = {}\n",
    "\n",
    "            for symbol in symbol_list:\n",
    "                try:\n",
    "                    print(f\"  ðŸ“¥ {symbol}...\")\n",
    "                    data = await ohlcv.get_historical_ohlcv(\n",
    "                        exchange_symbol=symbol,\n",
    "                        interval=\"240\",  # 4-hour intervals\n",
    "                        bars_count=50,\n",
    "                    )\n",
    "                    category_data[symbol] = data\n",
    "\n",
    "                    # Show latest price\n",
    "                    latest = data[-1]\n",
    "                    print(\n",
    "                        f\"    âœ… Latest: ${latest.close:.6f} (Vol: {latest.volume:,.0f})\"\n",
    "                    )\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"    âŒ Failed: {e}\")\n",
    "\n",
    "            all_data[category] = category_data\n",
    "\n",
    "    # Calculate volatility for each asset\n",
    "    print(\"\\nðŸ“ˆ Volatility Analysis (4-hour intervals, last 50 bars):\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "    for category, category_data in all_data.items():\n",
    "        print(f\"\\n{category}:\")\n",
    "        for symbol, data in category_data.items():\n",
    "            if len(data) > 1:\n",
    "                # Calculate price volatility (standard deviation of returns)\n",
    "                returns = []\n",
    "                for i in range(1, len(data)):\n",
    "                    ret = (data[i].close - data[i - 1].close) / data[i - 1].close\n",
    "                    returns.append(ret)\n",
    "\n",
    "                if returns:\n",
    "                    volatility = (\n",
    "                        sum((r - sum(returns) / len(returns)) ** 2 for r in returns)\n",
    "                        / len(returns)\n",
    "                    ) ** 0.5\n",
    "                    volatility_pct = volatility * 100\n",
    "\n",
    "                    print(\n",
    "                        f\"  {symbol:20} | Volatility: {volatility_pct:.3f}% | Latest: ${data[-1].close:.6f}\"\n",
    "                    )\n",
    "\n",
    "    return all_data\n",
    "\n",
    "\n",
    "# Fetch crypto and forex data\n",
    "crypto_forex_data = await fetch_crypto_and_forex_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fm6ipq6kth",
   "metadata": {},
   "source": [
    "## Real-time Data Streaming (Limited Demo)\n",
    "\n",
    "âš ï¸ **Note**: Real-time streaming is demonstrated with a limited time window to prevent infinite loops in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "qtiab9bamnn",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Starting limited real-time data stream (30 seconds)...\n",
      "Symbol: BINANCE:BTCUSDT (Bitcoin)\n",
      "--------------------------------------------------\n",
      "ðŸ“Š Bar 1: 2025-09-27T03:37:00+00:00 | Close: $109,651.00 | Volume: 1\n",
      "ðŸ“Š Bar 2: 2025-09-27T03:38:00+00:00 | Close: $109,690.81 | Volume: 47\n",
      "ðŸ“Š Bar 3: 2025-09-27T03:39:00+00:00 | Close: $109,690.80 | Volume: 1\n",
      "ðŸ“Š Bar 4: 2025-09-27T03:40:00+00:00 | Close: $109,689.98 | Volume: 12\n",
      "ðŸ“Š Bar 5: 2025-09-27T03:41:00+00:00 | Close: $109,659.89 | Volume: 5\n",
      "ðŸ“Š Bar 6: 2025-09-27T03:42:00+00:00 | Close: $109,665.55 | Volume: 11\n",
      "ðŸ“Š Bar 7: 2025-09-27T03:43:00+00:00 | Close: $109,637.44 | Volume: 14\n",
      "ðŸ“Š Bar 8: 2025-09-27T03:44:00+00:00 | Close: $109,635.98 | Volume: 7\n",
      "ðŸ“Š Bar 9: 2025-09-27T03:45:00+00:00 | Close: $109,617.18 | Volume: 2\n",
      "ðŸ“Š Bar 10: 2025-09-27T03:46:00+00:00 | Close: $109,635.98 | Volume: 1\n",
      "\n",
      "ðŸ“ˆ Received 10 bars, stopping demo\n",
      "\n",
      "âœ… Real-time demo completed. Received 10 bars.\n"
     ]
    }
   ],
   "source": [
    "async def limited_realtime_demo():\n",
    "    \"\"\"Demonstrate real-time streaming with a time limit.\"\"\"\n",
    "\n",
    "    print(\"ðŸš€ Starting limited real-time data stream (30 seconds)...\")\n",
    "    print(\"Symbol: BINANCE:BTCUSDT (Bitcoin)\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    start_time = asyncio.get_event_loop().time()\n",
    "    timeout_seconds = 30  # Limit to 30 seconds\n",
    "    bar_count = 0\n",
    "\n",
    "    try:\n",
    "        async with OHLCV() as ohlcv:\n",
    "            async for bar in ohlcv.get_ohlcv(\"BINANCE:BTCUSDT\", interval=\"1\"):\n",
    "                # Check timeout\n",
    "                if asyncio.get_event_loop().time() - start_time > timeout_seconds:\n",
    "                    print(f\"\\nâ° Demo timeout reached ({timeout_seconds}s)\")\n",
    "                    break\n",
    "\n",
    "                bar_count += 1\n",
    "                timestamp_str = convert_timestamp_to_iso(bar.timestamp)\n",
    "\n",
    "                print(\n",
    "                    f\"ðŸ“Š Bar {bar_count}: {timestamp_str} | \"\n",
    "                    f\"Close: ${bar.close:,.2f} | \"\n",
    "                    f\"Volume: {bar.volume:,.0f}\"\n",
    "                )\n",
    "\n",
    "                # Also limit by number of bars\n",
    "                if bar_count >= 10:\n",
    "                    print(f\"\\nðŸ“ˆ Received {bar_count} bars, stopping demo\")\n",
    "                    break\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Streaming error: {e}\")\n",
    "\n",
    "    print(f\"\\nâœ… Real-time demo completed. Received {bar_count} bars.\")\n",
    "\n",
    "\n",
    "# Run limited real-time demo\n",
    "await limited_realtime_demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7uvmq7e7cfr",
   "metadata": {},
   "source": [
    "## Error Handling and Best Practices\n",
    "\n",
    "Demonstration of proper error handling and best practices when working with TVKit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "289vajx2k3t",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ›¡ï¸  Error Handling and Best Practices\n",
      "=============================================\n",
      "\n",
      "1ï¸âƒ£  Invalid Symbol Handling:\n",
      "  ðŸ“¥ Attempting to fetch INVALID:SYMBOL...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-27 10:46:44,358 - ERROR - Series error received from TradingView during historical data fetch\n",
      "2025-09-27 10:46:44,359 - ERROR - Error details: {'m': 'series_error', 'p': ['cs_agjcfhbgwarx', 'sds_1', 's1', 'resolve error', 'hon1-charts-free-3-tvbs-xkye6-1@hon1-charts-free-3-tvbs-xkye6-1'], 't': 1758944804, 't_ms': 1758944804460}\n",
      "2025-09-27 10:46:44,359 - ERROR - Please check the interval - this timeframe may not be supported for the symbol\n",
      "2025-09-27 10:46:44,360 - ERROR - Also verify that bars_count is within valid range\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    âŒ Expected error: RuntimeError: No historical data received for symbol INVALID:SYMBOL\n",
      "  ðŸ“¥ Attempting to fetch BADEXCHANGE:BADSTOCK...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-27 10:46:45,053 - ERROR - Series error received from TradingView during historical data fetch\n",
      "2025-09-27 10:46:45,053 - ERROR - Error details: {'m': 'series_error', 'p': ['cs_ebkxvjoaqcnj', 'sds_1', 's1', 'resolve error', 'hon1-charts-free-3-tvbs-xkye6-1@hon1-charts-free-3-tvbs-xkye6-1'], 't': 1758944805, 't_ms': 1758944805155}\n",
      "2025-09-27 10:46:45,054 - ERROR - Please check the interval - this timeframe may not be supported for the symbol\n",
      "2025-09-27 10:46:45,054 - ERROR - Also verify that bars_count is within valid range\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    âŒ Expected error: RuntimeError: No historical data received for symbol BADEXCHANGE:BADSTOCK\n",
      "\n",
      "2ï¸âƒ£  Connection Resilience:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-27 10:46:45,622 - ERROR - Failed to export OHLCV data to JSON: [Errno 30] Read-only file system: '/invalid'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    âœ… Successfully fetched 5 bars\n",
      "\n",
      "3ï¸âƒ£  Export Error Handling:\n",
      "    âŒ Export failed: [Errno 30] Read-only file system: '/invalid'\n",
      "\n",
      "ðŸ’¡ Best Practices Summary:\n",
      "   â€¢ Always use async context managers (async with)\n",
      "   â€¢ Handle symbol validation errors gracefully\n",
      "   â€¢ Set appropriate timeouts for real-time streams\n",
      "   â€¢ Check export results for success status\n",
      "   â€¢ Use try-except blocks for robust error handling\n",
      "   â€¢ Validate data before processing\n"
     ]
    }
   ],
   "source": [
    "async def demonstrate_error_handling():\n",
    "    \"\"\"Show proper error handling techniques with TVKit.\"\"\"\n",
    "\n",
    "    print(\"ðŸ›¡ï¸  Error Handling and Best Practices\")\n",
    "    print(\"=\" * 45)\n",
    "\n",
    "    # 1. Handle invalid symbols gracefully\n",
    "    print(\"\\n1ï¸âƒ£  Invalid Symbol Handling:\")\n",
    "    invalid_symbols = [\"INVALID:SYMBOL\", \"BADEXCHANGE:BADSTOCK\"]\n",
    "\n",
    "    async with OHLCV() as ohlcv:\n",
    "        for symbol in invalid_symbols:\n",
    "            try:\n",
    "                print(f\"  ðŸ“¥ Attempting to fetch {symbol}...\")\n",
    "                data = await ohlcv.get_historical_ohlcv(\n",
    "                    exchange_symbol=symbol, interval=\"1D\", bars_count=10\n",
    "                )\n",
    "                print(f\"    âœ… Success: Got {len(data)} bars\")\n",
    "            except Exception as e:\n",
    "                print(f\"    âŒ Expected error: {type(e).__name__}: {e}\")\n",
    "\n",
    "    # 2. Handle network timeouts and connection issues\n",
    "    print(\"\\n2ï¸âƒ£  Connection Resilience:\")\n",
    "\n",
    "    try:\n",
    "        async with OHLCV() as ohlcv:\n",
    "            # This should work normally\n",
    "            data = await ohlcv.get_historical_ohlcv(\n",
    "                exchange_symbol=\"NASDAQ:AAPL\", interval=\"1D\", bars_count=5\n",
    "            )\n",
    "            print(f\"    âœ… Successfully fetched {len(data)} bars\")\n",
    "    except Exception as e:\n",
    "        print(f\"    âŒ Connection error: {e}\")\n",
    "\n",
    "    # 3. Export error handling\n",
    "    print(\"\\n3ï¸âƒ£  Export Error Handling:\")\n",
    "\n",
    "    try:\n",
    "        exporter = DataExporter()\n",
    "\n",
    "        # Try to export to an invalid path\n",
    "        result = await exporter.export_ohlcv_data(\n",
    "            apple_data[:5],  # Use small subset\n",
    "            ExportFormat.JSON,\n",
    "            file_path=\"/invalid/path/cannot_write_here.json\",\n",
    "        )\n",
    "\n",
    "        if result.success:\n",
    "            print(\"    âœ… Export successful\")\n",
    "        else:\n",
    "            print(f\"    âŒ Export failed: {result.error_message}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"    âŒ Export exception: {type(e).__name__}: {e}\")\n",
    "\n",
    "    # 4. Best practices summary\n",
    "    print(\"\\nðŸ’¡ Best Practices Summary:\")\n",
    "    print(\"   â€¢ Always use async context managers (async with)\")\n",
    "    print(\"   â€¢ Handle symbol validation errors gracefully\")\n",
    "    print(\"   â€¢ Set appropriate timeouts for real-time streams\")\n",
    "    print(\"   â€¢ Check export results for success status\")\n",
    "    print(\"   â€¢ Use try-except blocks for robust error handling\")\n",
    "    print(\"   â€¢ Validate data before processing\")\n",
    "\n",
    "\n",
    "# Demonstrate error handling\n",
    "await demonstrate_error_handling()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qv3hky6ml6g",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook has demonstrated the comprehensive capabilities of TVKit:\n",
    "\n",
    "### âœ… Completed Examples\n",
    "\n",
    "- **Basic OHLCV Data Fetching** - Retrieved historical market data for Apple stock\n",
    "- **Multi-format Data Export** - Exported to Polars DataFrame, JSON, and CSV formats\n",
    "- **Multi-symbol Operations** - Compared performance across multiple stocks\n",
    "- **Cryptocurrency & Forex** - Demonstrated support for various asset classes\n",
    "- **Macro Liquidity Indicators** - Accessed INDEX:NDFI and USI:PCC for quantitative analysis\n",
    "- **Quantitative Integration** - Showed integration with systematic trading models\n",
    "- **Real-time Streaming** - Limited demo of live data streaming\n",
    "- **Error Handling** - Best practices for robust applications\n",
    "\n",
    "### ðŸ”§ Key Features Highlighted\n",
    "\n",
    "- **Async Architecture** - All operations use modern async/await patterns\n",
    "- **Type Safety** - Comprehensive Pydantic models for data validation\n",
    "- **Multiple Asset Classes** - Stocks, crypto, forex, and macro indicators\n",
    "- **Flexible Export System** - Support for Polars, JSON, CSV with custom options\n",
    "- **Real-time Capabilities** - WebSocket streaming for live market data\n",
    "- **Quantitative Analysis** - Tools for systematic trading and risk management\n",
    "- **Macro Indicators** - Access to essential liquidity and breadth metrics\n",
    "- **Error Resilience** - Robust error handling and validation\n",
    "\n",
    "### ðŸ“Š Macro Indicators Covered\n",
    "\n",
    "- **INDEX:NDFI** - Net Demand For Income indicator for market breadth analysis\n",
    "- **USI:PCC** - Put/Call Ratio for sentiment and liquidity analysis\n",
    "- **Quantitative Integration** - Examples for systematic trading strategies\n",
    "- **Risk Management** - Regime detection and portfolio optimization\n",
    "\n",
    "### ðŸ“š Next Steps\n",
    "\n",
    "- Explore the full [TVKit documentation](https://github.com/your-repo/tvkit)\n",
    "- Check out additional examples in the `examples/` directory\n",
    "- Review the API reference for advanced features\n",
    "- Consider integrating TVKit into your financial analysis workflows\n",
    "- Implement macro indicators in your quantitative trading models\n",
    "\n",
    "**Happy Trading! ðŸ“ˆ**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4dh98r3r6j",
   "metadata": {},
   "source": [
    "## Macro Liquidity and Market Breadth Indicators\n",
    "\n",
    "This section demonstrates accessing macro liquidity and market breadth indicators that are essential for quantitative liquidity models, macro regime detection, and systematic trading strategies.\n",
    "\n",
    "### Key Indicators Covered:\n",
    "- **INDEX:NDFI** - Net Demand For Income (Market Breadth Indicator)\n",
    "- **USI:PCC** - Put/Call Ratio (Liquidity and Sentiment Indicator)\n",
    "\n",
    "These indicators are widely used in professional research for:\n",
    "- **Liquidity Regime Analysis** - Understanding market liquidity conditions\n",
    "- **Risk Management** - Macro trend detection and regime changes  \n",
    "- **Portfolio Optimization** - Systematic trading strategy development\n",
    "- **Market Timing** - Entry/exit signal generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ary01uidfj",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ¯ Fetching Macro Liquidity and Market Breadth Indicators\n",
      "=================================================================\n",
      "\n",
      "ðŸ“Š Fetching Net Demand For Income (INDEX:NDFI)...\n",
      "   ðŸ“ Description: Market breadth indicator measuring income-seeking demand\n",
      "   ðŸŽ¯ Use Case: Liquidity regime detection, macro trend analysis\n",
      "   âœ… Successfully fetched 100 bars\n",
      "   ðŸ“… Data range: 2025-05-06 to 2025-09-26\n",
      "   ðŸ“ˆ Latest value: 47.520000\n",
      "   ðŸ“Š Statistics: Min=38.610000, Max=85.140000, Avg=63.658800\n",
      "   ðŸ“‰ Volatility: 14.696212\n",
      "\n",
      "ðŸ“Š Fetching Put/Call Ratio (USI:PCC)...\n",
      "   ðŸ“ Description: Options sentiment and liquidity indicator\n",
      "   ðŸŽ¯ Use Case: Market sentiment, volatility prediction, contrarian signals\n",
      "   âœ… Successfully fetched 100 bars\n",
      "   ðŸ“… Data range: 2025-05-06 to 2025-09-26\n",
      "   ðŸ“ˆ Latest value: 0.775063\n",
      "   ðŸ“Š Statistics: Min=0.694588, Max=1.071995, Avg=0.849060\n",
      "   ðŸ“‰ Volatility: 0.073580\n"
     ]
    }
   ],
   "source": [
    "async def fetch_macro_liquidity_indicators():\n",
    "    \"\"\"\n",
    "    Fetch macro liquidity and market breadth indicators.\n",
    "\n",
    "    These indicators are essential for:\n",
    "    - Macro liquidity regime detection\n",
    "    - Market breadth analysis\n",
    "    - Systematic trading strategies\n",
    "    - Risk management and portfolio optimization\n",
    "    \"\"\"\n",
    "\n",
    "    # Define macro indicators with descriptions\n",
    "    macro_indicators = {\n",
    "        \"INDEX:NDFI\": {\n",
    "            \"name\": \"Net Demand For Income\",\n",
    "            \"description\": \"Market breadth indicator measuring income-seeking demand\",\n",
    "            \"use_case\": \"Liquidity regime detection, macro trend analysis\",\n",
    "        },\n",
    "        \"USI:PCC\": {\n",
    "            \"name\": \"Put/Call Ratio\",\n",
    "            \"description\": \"Options sentiment and liquidity indicator\",\n",
    "            \"use_case\": \"Market sentiment, volatility prediction, contrarian signals\",\n",
    "        },\n",
    "    }\n",
    "\n",
    "    indicator_data = {}\n",
    "\n",
    "    print(\"ðŸŽ¯ Fetching Macro Liquidity and Market Breadth Indicators\")\n",
    "    print(\"=\" * 65)\n",
    "\n",
    "    async with OHLCV() as ohlcv:\n",
    "        for symbol, info in macro_indicators.items():\n",
    "            try:\n",
    "                print(f\"\\nðŸ“Š Fetching {info['name']} ({symbol})...\")\n",
    "                print(f\"   ðŸ“ Description: {info['description']}\")\n",
    "                print(f\"   ðŸŽ¯ Use Case: {info['use_case']}\")\n",
    "\n",
    "                # Fetch historical data - using daily intervals for macro analysis\n",
    "                data = await ohlcv.get_historical_ohlcv(\n",
    "                    exchange_symbol=symbol,\n",
    "                    interval=\"1D\",  # Daily data for macro analysis\n",
    "                    bars_count=100,  # ~3-4 months of data\n",
    "                )\n",
    "\n",
    "                indicator_data[symbol] = {\"data\": data, \"info\": info}\n",
    "\n",
    "                # Display latest values and basic statistics\n",
    "                if data:\n",
    "                    latest = data[-1]\n",
    "                    earliest = data[0]\n",
    "\n",
    "                    # Calculate some basic statistics\n",
    "                    values = [bar.close for bar in data]\n",
    "                    avg_value = sum(values) / len(values)\n",
    "                    max_value = max(values)\n",
    "                    min_value = min(values)\n",
    "\n",
    "                    # Calculate volatility (standard deviation)\n",
    "                    variance = sum((x - avg_value) ** 2 for x in values) / len(values)\n",
    "                    volatility = variance**0.5\n",
    "\n",
    "                    print(f\"   âœ… Successfully fetched {len(data)} bars\")\n",
    "                    print(\n",
    "                        f\"   ðŸ“… Data range: {convert_timestamp_to_iso(earliest.timestamp)[:10]} to {convert_timestamp_to_iso(latest.timestamp)[:10]}\"\n",
    "                    )\n",
    "                    print(f\"   ðŸ“ˆ Latest value: {latest.close:.6f}\")\n",
    "                    print(\n",
    "                        f\"   ðŸ“Š Statistics: Min={min_value:.6f}, Max={max_value:.6f}, Avg={avg_value:.6f}\"\n",
    "                    )\n",
    "                    print(f\"   ðŸ“‰ Volatility: {volatility:.6f}\")\n",
    "\n",
    "                else:\n",
    "                    print(\"   âŒ No data received\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"   âŒ Error fetching {symbol}: {type(e).__name__}: {e}\")\n",
    "                indicator_data[symbol] = {\"error\": str(e), \"info\": info}\n",
    "\n",
    "    return indicator_data\n",
    "\n",
    "\n",
    "# Fetch macro indicators\n",
    "macro_data = await fetch_macro_liquidity_indicators()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fnww9frr3su",
   "metadata": {},
   "source": [
    "### Macro Indicator Analysis and Export\n",
    "\n",
    "Export the macro indicators to various formats for further analysis and integrate them with quantitative models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "l9v0gu5ama",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”¬ Analyzing Macro Indicators for Quantitative Models\n",
      "=======================================================\n",
      "\n",
      "ðŸ“Š Analyzing Net Demand For Income (INDEX:NDFI)\n",
      "--------------------------------------------------\n",
      "   ðŸ“ˆ DataFrame shape: (100, 17)\n",
      "   ðŸ“ˆ Current Value: 47.520000\n",
      "   ðŸ“Š Recent Avg (20d): 44.748000\n",
      "   ðŸ“Š Historical Avg: 49.995000\n",
      "   ðŸ“ˆ Trend Change: -10.50%\n",
      "   ðŸ“‰ Recent Volatility: 3.380527\n",
      "   ðŸ“Š Current Percentile: 20.0%\n",
      "   ðŸŽ¯ Signal: Low income demand - Potential market weakness\n",
      "   ðŸ’¾ Exported to CSV: tvkit_exports/macro_index_ndfi_data.csv\n",
      "   ðŸ’¾ Exported to JSON: tvkit_exports/macro_index_ndfi_data.json\n",
      "\n",
      "ðŸ“Š Analyzing Put/Call Ratio (USI:PCC)\n",
      "--------------------------------------------------\n",
      "   ðŸ“ˆ DataFrame shape: (100, 17)\n",
      "   ðŸ“ˆ Current Value: 0.775063\n",
      "   ðŸ“Š Recent Avg (20d): 0.839245\n",
      "   ðŸ“Š Historical Avg: 0.854159\n",
      "   ðŸ“ˆ Trend Change: -1.75%\n",
      "   ðŸ“‰ Recent Volatility: 0.079249\n",
      "   ðŸ“Š Current Percentile: 20.0%\n",
      "   ðŸŽ¯ Signal: Low put/call ratio - Potential market complacency\n",
      "   ðŸ’¾ Exported to CSV: tvkit_exports/macro_usi_pcc_data.csv\n",
      "   ðŸ’¾ Exported to JSON: tvkit_exports/macro_usi_pcc_data.json\n",
      "\n",
      "ðŸŽ¯ Macro Liquidity Analysis Summary\n",
      "========================================\n",
      "\n",
      "Net Demand For Income (INDEX:NDFI):\n",
      "  Current Level: 20.0th percentile\n",
      "  Trend: -10.50% (recent vs historical)\n",
      "  Use in Models: Liquidity regime detection, macro trend analysis\n",
      "\n",
      "Put/Call Ratio (USI:PCC):\n",
      "  Current Level: 20.0th percentile\n",
      "  Trend: -1.75% (recent vs historical)\n",
      "  Use in Models: Market sentiment, volatility prediction, contrarian signals\n"
     ]
    }
   ],
   "source": [
    "async def analyze_and_export_macro_indicators(macro_data):\n",
    "    \"\"\"\n",
    "    Analyze macro indicators and export to multiple formats.\n",
    "\n",
    "    This demonstrates how to:\n",
    "    - Process macro liquidity indicators for quantitative analysis\n",
    "    - Export data for integration with systematic trading models\n",
    "    - Calculate key metrics for liquidity regime detection\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"ðŸ”¬ Analyzing Macro Indicators for Quantitative Models\")\n",
    "    print(\"=\" * 55)\n",
    "\n",
    "    exporter = DataExporter()\n",
    "    analysis_results = {}\n",
    "\n",
    "    for symbol, indicator_info in macro_data.items():\n",
    "        if \"error\" in indicator_info:\n",
    "            print(f\"\\nâŒ Skipping {symbol} due to error: {indicator_info['error']}\")\n",
    "            continue\n",
    "\n",
    "        data = indicator_info[\"data\"]\n",
    "        info = indicator_info[\"info\"]\n",
    "\n",
    "        if not data:\n",
    "            print(f\"\\nâŒ No data available for {symbol}\")\n",
    "            continue\n",
    "\n",
    "        print(f\"\\nðŸ“Š Analyzing {info['name']} ({symbol})\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "        # Convert to DataFrame for analysis\n",
    "        df = await exporter.to_polars(data, add_analysis=True)\n",
    "        print(f\"   ðŸ“ˆ DataFrame shape: {df.shape}\")\n",
    "\n",
    "        # Calculate additional metrics for macro analysis\n",
    "        if len(data) > 20:  # Ensure sufficient data\n",
    "            # Recent vs Historical comparison (last 20 days vs previous 20)\n",
    "            recent_values = [bar.close for bar in data[-20:]]\n",
    "            historical_values = (\n",
    "                [bar.close for bar in data[-40:-20]]\n",
    "                if len(data) >= 40\n",
    "                else [bar.close for bar in data[:-20]]\n",
    "            )\n",
    "\n",
    "            recent_avg = sum(recent_values) / len(recent_values)\n",
    "            historical_avg = (\n",
    "                sum(historical_values) / len(historical_values)\n",
    "                if historical_values\n",
    "                else recent_avg\n",
    "            )\n",
    "\n",
    "            # Trend analysis\n",
    "            trend_change = (\n",
    "                ((recent_avg - historical_avg) / historical_avg * 100)\n",
    "                if historical_avg != 0\n",
    "                else 0\n",
    "            )\n",
    "\n",
    "            # Volatility analysis\n",
    "            recent_volatility = (\n",
    "                sum((x - recent_avg) ** 2 for x in recent_values) / len(recent_values)\n",
    "            ) ** 0.5\n",
    "\n",
    "            # Percentile analysis (current position relative to historical range)\n",
    "            all_values = [bar.close for bar in data]\n",
    "            current_value = data[-1].close\n",
    "            sorted_values = sorted(all_values)\n",
    "            percentile = (\n",
    "                sum(1 for v in sorted_values if v <= current_value) / len(sorted_values)\n",
    "            ) * 100\n",
    "\n",
    "            analysis_results[symbol] = {\n",
    "                \"name\": info[\"name\"],\n",
    "                \"current_value\": current_value,\n",
    "                \"recent_avg\": recent_avg,\n",
    "                \"historical_avg\": historical_avg,\n",
    "                \"trend_change_pct\": trend_change,\n",
    "                \"volatility\": recent_volatility,\n",
    "                \"percentile\": percentile,\n",
    "                \"use_case\": info[\"use_case\"],\n",
    "            }\n",
    "\n",
    "            print(f\"   ðŸ“ˆ Current Value: {current_value:.6f}\")\n",
    "            print(f\"   ðŸ“Š Recent Avg (20d): {recent_avg:.6f}\")\n",
    "            print(f\"   ðŸ“Š Historical Avg: {historical_avg:.6f}\")\n",
    "            print(f\"   ðŸ“ˆ Trend Change: {trend_change:+.2f}%\")\n",
    "            print(f\"   ðŸ“‰ Recent Volatility: {recent_volatility:.6f}\")\n",
    "            print(f\"   ðŸ“Š Current Percentile: {percentile:.1f}%\")\n",
    "\n",
    "            # Interpretation for trading strategies\n",
    "            if symbol == \"INDEX:NDFI\":\n",
    "                if percentile > 75:\n",
    "                    signal = \"High income demand - Potential market strength\"\n",
    "                elif percentile < 25:\n",
    "                    signal = \"Low income demand - Potential market weakness\"\n",
    "                else:\n",
    "                    signal = \"Neutral income demand\"\n",
    "                print(f\"   ðŸŽ¯ Signal: {signal}\")\n",
    "\n",
    "            elif symbol == \"USI:PCC\":\n",
    "                if percentile > 75:\n",
    "                    signal = \"High put/call ratio - Potential contrarian bullish signal\"\n",
    "                elif percentile < 25:\n",
    "                    signal = \"Low put/call ratio - Potential market complacency\"\n",
    "                else:\n",
    "                    signal = \"Neutral sentiment\"\n",
    "                print(f\"   ðŸŽ¯ Signal: {signal}\")\n",
    "\n",
    "        # Export individual indicator data\n",
    "        try:\n",
    "            # Export to CSV for systematic trading models\n",
    "            csv_path = await exporter.to_csv(\n",
    "                data,\n",
    "                f\"./tvkit_exports/macro_{symbol.replace(':', '_').lower()}_data.csv\",\n",
    "                include_metadata=True,\n",
    "                timestamp_format=\"iso\",\n",
    "            )\n",
    "            print(f\"   ðŸ’¾ Exported to CSV: {csv_path}\")\n",
    "\n",
    "            # Export to JSON for web applications\n",
    "            json_path = await exporter.to_json(\n",
    "                data,\n",
    "                f\"./tvkit_exports/macro_{symbol.replace(':', '_').lower()}_data.json\",\n",
    "                include_metadata=True,\n",
    "                indent=2,\n",
    "            )\n",
    "            print(f\"   ðŸ’¾ Exported to JSON: {json_path}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"   âŒ Export error: {e}\")\n",
    "\n",
    "    # Summary analysis\n",
    "    print(\"\\nðŸŽ¯ Macro Liquidity Analysis Summary\")\n",
    "    print(\"=\" * 40)\n",
    "\n",
    "    for symbol, analysis in analysis_results.items():\n",
    "        print(f\"\\n{analysis['name']} ({symbol}):\")\n",
    "        print(f\"  Current Level: {analysis['percentile']:.1f}th percentile\")\n",
    "        print(f\"  Trend: {analysis['trend_change_pct']:+.2f}% (recent vs historical)\")\n",
    "        print(f\"  Use in Models: {analysis['use_case']}\")\n",
    "\n",
    "    return analysis_results\n",
    "\n",
    "\n",
    "# Analyze and export macro indicators\n",
    "if macro_data:\n",
    "    macro_analysis = await analyze_and_export_macro_indicators(macro_data)\n",
    "else:\n",
    "    print(\"âš ï¸ No macro data available for analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lmc1azjj0fg",
   "metadata": {},
   "source": [
    "### Integration with Quantitative Models\n",
    "\n",
    "This section shows how to integrate macro indicators with quantitative trading strategies and risk management frameworks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ujo4vfpo1g",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§® Quantitative Model Integration Examples\n",
      "=============================================\n",
      "\n",
      "1ï¸âƒ£ Liquidity Regime Classification\n",
      "-----------------------------------\n",
      "   Net Demand For Income (INDEX:NDFI):\n",
      "   ðŸ“Š Regime: LOW_LIQUIDITY_CONTRACTING\n",
      "   ðŸŽ¯ Confidence: 80.0%\n",
      "   ðŸ“ˆ Current Level: 20.0th percentile\n",
      "   Put/Call Ratio (USI:PCC):\n",
      "   ðŸ“Š Regime: LOW_FEAR\n",
      "   ðŸŽ¯ Confidence: 70.0%\n",
      "   ðŸ“ˆ Current Level: 20.0th percentile\n",
      "\n",
      "2ï¸âƒ£ Risk Management Framework\n",
      "------------------------------\n",
      "   ðŸ“Š Combined Risk Score: 3/4 (1.50)\n",
      "   âš ï¸ Risk Level: HIGH\n",
      "   ðŸŽ¯ Suggested Action: Reduce position sizes, increase cash allocation\n",
      "\n",
      "3ï¸âƒ£ Trading Signal Generation\n",
      "------------------------------\n",
      "   ðŸ“Š No clear trading signals detected\n",
      "\n",
      "4ï¸âƒ£ Code Template for Systematic Models\n",
      "----------------------------------------\n",
      "\n",
      "# Example integration with systematic trading model\n",
      "def update_model_with_macro_indicators(macro_data):\n",
      "    \"\"\"\n",
      "    Template for integrating macro indicators into systematic models.\n",
      "    \"\"\"\n",
      "\n",
      "    # Extract indicator values\n",
      "    ndfi_percentile = macro_data.get(\"INDEX:NDFI\", {}).get(\"percentile\", 50)\n",
      "    pcc_percentile = macro_data.get(\"USI:PCC\", {}).get(\"percentile\", 50)\n",
      "\n",
      "    # Regime detection logic\n",
      "    liquidity_regime = classify_liquidity_regime(ndfi_percentile)\n",
      "    sentiment_regime = classify_sentiment_regime(pcc_percentile)\n",
      "\n",
      "    # Adjust model parameters based on regime\n",
      "    if liquidity_regime == \"LOW_LIQUIDITY\":\n",
      "        position_sizing_multiplier = 0.5  # Reduce positions\n",
      "        volatility_target = 0.10  # Lower vol target\n",
      "    else:\n",
      "        position_sizing_multiplier = 1.0\n",
      "        volatility_target = 0.15\n",
      "\n",
      "    return {\n",
      "        \"position_sizing\": position_sizing_multiplier,\n",
      "        \"volatility_target\": volatility_target,\n",
      "        \"regime_signals\": [liquidity_regime, sentiment_regime]\n",
      "    }\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "def demonstrate_quantitative_integration(macro_analysis):\n",
    "    \"\"\"\n",
    "    Demonstrate how to integrate macro indicators into quantitative models.\n",
    "\n",
    "    This shows practical applications for:\n",
    "    - Systematic trading strategies\n",
    "    - Risk regime detection\n",
    "    - Portfolio allocation models\n",
    "    - Market timing systems\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"ðŸ§® Quantitative Model Integration Examples\")\n",
    "    print(\"=\" * 45)\n",
    "\n",
    "    if not macro_analysis:\n",
    "        print(\"âš ï¸ No macro analysis data available for integration examples\")\n",
    "        return\n",
    "\n",
    "    # Example 1: Liquidity Regime Classification\n",
    "    print(\"\\n1ï¸âƒ£ Liquidity Regime Classification\")\n",
    "    print(\"-\" * 35)\n",
    "\n",
    "    for symbol, analysis in macro_analysis.items():\n",
    "        regime = \"UNKNOWN\"\n",
    "        confidence = 0\n",
    "\n",
    "        if symbol == \"INDEX:NDFI\":\n",
    "            # NDFI-based liquidity regime detection\n",
    "            percentile = analysis[\"percentile\"]\n",
    "            trend = analysis[\"trend_change_pct\"]\n",
    "\n",
    "            if percentile > 75 and trend > 0:\n",
    "                regime = \"HIGH_LIQUIDITY_EXPANDING\"\n",
    "                confidence = 0.85\n",
    "            elif percentile > 60:\n",
    "                regime = \"HIGH_LIQUIDITY_STABLE\"\n",
    "                confidence = 0.70\n",
    "            elif percentile < 25 and trend < 0:\n",
    "                regime = \"LOW_LIQUIDITY_CONTRACTING\"\n",
    "                confidence = 0.80\n",
    "            elif percentile < 40:\n",
    "                regime = \"LOW_LIQUIDITY_STABLE\"\n",
    "                confidence = 0.65\n",
    "            else:\n",
    "                regime = \"NEUTRAL_LIQUIDITY\"\n",
    "                confidence = 0.50\n",
    "\n",
    "        elif symbol == \"USI:PCC\":\n",
    "            # Put/Call ratio sentiment analysis\n",
    "            percentile = analysis[\"percentile\"]\n",
    "\n",
    "            if percentile > 80:\n",
    "                regime = \"EXTREME_FEAR\"\n",
    "                confidence = 0.85\n",
    "            elif percentile > 60:\n",
    "                regime = \"ELEVATED_FEAR\"\n",
    "                confidence = 0.70\n",
    "            elif percentile < 20:\n",
    "                regime = \"EXTREME_COMPLACENCY\"\n",
    "                confidence = 0.85\n",
    "            elif percentile < 40:\n",
    "                regime = \"LOW_FEAR\"\n",
    "                confidence = 0.70\n",
    "            else:\n",
    "                regime = \"NEUTRAL_SENTIMENT\"\n",
    "                confidence = 0.50\n",
    "\n",
    "        print(f\"   {analysis['name']} ({symbol}):\")\n",
    "        print(f\"   ðŸ“Š Regime: {regime}\")\n",
    "        print(f\"   ðŸŽ¯ Confidence: {confidence:.1%}\")\n",
    "        print(f\"   ðŸ“ˆ Current Level: {analysis['percentile']:.1f}th percentile\")\n",
    "\n",
    "    # Example 2: Risk Management Signals\n",
    "    print(\"\\n2ï¸âƒ£ Risk Management Framework\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "    # Combine indicators for risk assessment\n",
    "    risk_score = 0\n",
    "    signal_count = 0\n",
    "\n",
    "    for symbol, analysis in macro_analysis.items():\n",
    "        if symbol == \"INDEX:NDFI\":\n",
    "            # Low NDFI = higher risk\n",
    "            if analysis[\"percentile\"] < 25:\n",
    "                risk_score += 2\n",
    "            elif analysis[\"percentile\"] < 50:\n",
    "                risk_score += 1\n",
    "            signal_count += 1\n",
    "\n",
    "        elif symbol == \"USI:PCC\":\n",
    "            # Extreme levels indicate higher volatility risk\n",
    "            if analysis[\"percentile\"] > 75 or analysis[\"percentile\"] < 25:\n",
    "                risk_score += 1\n",
    "            signal_count += 1\n",
    "\n",
    "    if signal_count > 0:\n",
    "        avg_risk = risk_score / signal_count\n",
    "\n",
    "        if avg_risk >= 1.5:\n",
    "            risk_level = \"HIGH\"\n",
    "            portfolio_action = \"Reduce position sizes, increase cash allocation\"\n",
    "        elif avg_risk >= 0.75:\n",
    "            risk_level = \"MEDIUM\"\n",
    "            portfolio_action = \"Moderate position sizing, maintain diversification\"\n",
    "        else:\n",
    "            risk_level = \"LOW\"\n",
    "            portfolio_action = \"Normal position sizing, consider growth allocation\"\n",
    "\n",
    "        print(\n",
    "            f\"   ðŸ“Š Combined Risk Score: {risk_score}/{signal_count * 2} ({avg_risk:.2f})\"\n",
    "        )\n",
    "        print(f\"   âš ï¸ Risk Level: {risk_level}\")\n",
    "        print(f\"   ðŸŽ¯ Suggested Action: {portfolio_action}\")\n",
    "\n",
    "    # Example 3: Signal Generation for Trading\n",
    "    print(\"\\n3ï¸âƒ£ Trading Signal Generation\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "    signals = []\n",
    "\n",
    "    for symbol, analysis in macro_analysis.items():\n",
    "        if symbol == \"INDEX:NDFI\":\n",
    "            if analysis[\"percentile\"] < 25 and analysis[\"trend_change_pct\"] > 5:\n",
    "                signals.append(\"NDFI Reversal: Potential bullish divergence\")\n",
    "            elif analysis[\"percentile\"] > 75 and analysis[\"trend_change_pct\"] < -5:\n",
    "                signals.append(\"NDFI Peak: Potential bearish reversal\")\n",
    "\n",
    "        elif symbol == \"USI:PCC\":\n",
    "            if analysis[\"percentile\"] > 80:\n",
    "                signals.append(\"PCC Extreme Fear: Contrarian bullish opportunity\")\n",
    "            elif analysis[\"percentile\"] < 20:\n",
    "                signals.append(\"PCC Complacency: Monitor for volatility increase\")\n",
    "\n",
    "    if signals:\n",
    "        for i, signal in enumerate(signals, 1):\n",
    "            print(f\"   {i}. {signal}\")\n",
    "    else:\n",
    "        print(\"   ðŸ“Š No clear trading signals detected\")\n",
    "\n",
    "    # Example 4: Model Integration Code Template\n",
    "    print(\"\\n4ï¸âƒ£ Code Template for Systematic Models\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "    template = '''\n",
    "# Example integration with systematic trading model\n",
    "def update_model_with_macro_indicators(macro_data):\n",
    "    \"\"\"\n",
    "    Template for integrating macro indicators into systematic models.\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract indicator values\n",
    "    ndfi_percentile = macro_data.get(\"INDEX:NDFI\", {}).get(\"percentile\", 50)\n",
    "    pcc_percentile = macro_data.get(\"USI:PCC\", {}).get(\"percentile\", 50)\n",
    "\n",
    "    # Regime detection logic\n",
    "    liquidity_regime = classify_liquidity_regime(ndfi_percentile)\n",
    "    sentiment_regime = classify_sentiment_regime(pcc_percentile)\n",
    "\n",
    "    # Adjust model parameters based on regime\n",
    "    if liquidity_regime == \"LOW_LIQUIDITY\":\n",
    "        position_sizing_multiplier = 0.5  # Reduce positions\n",
    "        volatility_target = 0.10  # Lower vol target\n",
    "    else:\n",
    "        position_sizing_multiplier = 1.0\n",
    "        volatility_target = 0.15\n",
    "\n",
    "    return {\n",
    "        \"position_sizing\": position_sizing_multiplier,\n",
    "        \"volatility_target\": volatility_target,\n",
    "        \"regime_signals\": [liquidity_regime, sentiment_regime]\n",
    "    }\n",
    "    '''\n",
    "\n",
    "    print(template)\n",
    "\n",
    "    return {\n",
    "        \"risk_assessment\": {\n",
    "            \"risk_score\": risk_score if \"risk_score\" in locals() else 0,\n",
    "            \"risk_level\": risk_level if \"risk_level\" in locals() else \"UNKNOWN\",\n",
    "        },\n",
    "        \"trading_signals\": signals,\n",
    "        \"regime_classification\": {\n",
    "            symbol: regime for symbol, analysis in macro_analysis.items()\n",
    "        },\n",
    "    }\n",
    "\n",
    "\n",
    "# Run quantitative integration examples\n",
    "if \"macro_analysis\" in locals() and macro_analysis:\n",
    "    quant_results = demonstrate_quantitative_integration(macro_analysis)\n",
    "else:\n",
    "    print(\"âš ï¸ Running integration examples with sample data...\")\n",
    "    # Provide example for demonstration\n",
    "    sample_analysis = {\n",
    "        \"INDEX:NDFI\": {\n",
    "            \"name\": \"Net Demand For Income\",\n",
    "            \"percentile\": 65.0,\n",
    "            \"trend_change_pct\": 2.5,\n",
    "        },\n",
    "        \"USI:PCC\": {\n",
    "            \"name\": \"Put/Call Ratio\",\n",
    "            \"percentile\": 75.0,\n",
    "            \"trend_change_pct\": -1.2,\n",
    "        },\n",
    "    }\n",
    "    quant_results = demonstrate_quantitative_integration(sample_analysis)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tvkit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
